// Code generated by internal/simd/cmd/generator. DO NOT EDIT.

//go:build !noasm && amd64

#include "textflag.h"

TEXT ·int4L2DistanceAvx512(SB), NOSPLIT, $0-48
	MOVQ query+0(FP), DI
	MOVQ code+8(FP), SI
	MOVQ dim+16(FP), DX
	MOVQ minVal+24(FP), CX
	MOVQ diff+32(FP), R8
	MOVQ out+40(FP), R9

	LONG $0x04ec8348 // subq	$0x4, %rsp
	LONG $0x888889b8; BYTE $0x3d // movl	$0x3d888889, %eax       # imm = 0x3D888889
	LONG $0xc06ef9c5 // vmovd	%eax, %xmm0
	LONG $0x487df262; WORD $0xc018 // vbroadcastss	%xmm0, %zmm0
	LONG $0x0f0f0fb8; BYTE $0x0f // movl	$0xf0f0f0f, %eax        # imm = 0xF0F0F0F
	LONG $0xc86ef9c5 // vmovd	%eax, %xmm1
	LONG $0x5879e2c4; BYTE $0xc9 // vpbroadcastd	%xmm1, %xmm1
	LONG $0x40fa8348 // cmpq	$0x40, %rdx
	WORD $0x0f7d // jge	0x36 <int4L2DistanceAvx512+0x36>
	LONG $0xd257e8c5 // vxorps	%xmm2, %xmm2, %xmm2
	WORD $0xc031 // xorl	%eax, %eax
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0x000151e9; BYTE $0x00 // jmp	0x187 <int4L2DistanceAvx512+0x187>
LBB0_4:
	LONG $0xc0528d4c // leaq	-0x40(%rdx), %r10
	LONG $0xe457d8c5 // vxorps	%xmm4, %xmm4, %xmm4
	WORD $0xc031 // xorl	%eax, %eax
	WORD $0x8949; BYTE $0xf3 // movq	%rsi, %r11
	LONG $0xed57d0c5 // vxorps	%xmm5, %xmm5, %xmm5
LBB0_5:
	QUAD $0x000001008b180f41 // prefetcht0	0x100(%r11)
	QUAD $0x00000200878c180f // prefetcht0	0x200(%rdi,%rax,4)
	LONG $0x6f7ac1c4; BYTE $0x13 // vmovdqu	(%r11), %xmm2
	LONG $0x6f7ac1c4; WORD $0x105b // vmovdqu	0x10(%r11), %xmm3
	LONG $0xd271c9c5; BYTE $0x04 // vpsrlw	$0x4, %xmm2, %xmm6
	LONG $0xf1dbc9c5 // vpand	%xmm1, %xmm6, %xmm6
	LONG $0xd1dbe9c5 // vpand	%xmm1, %xmm2, %xmm2
	LONG $0xfa60c9c5 // vpunpcklbw	%xmm2, %xmm6, %xmm7 # xmm7 = xmm6[0],xmm2[0],xmm6[1],xmm2[1],xmm6[2],xmm2[2],xmm6[3],xmm2[3],xmm6[4],xmm2[4],xmm6[5],xmm2[5],xmm6[6],xmm2[6],xmm6[7],xmm2[7]
	LONG $0xd268c9c5 // vpunpckhbw	%xmm2, %xmm6, %xmm2 # xmm2 = xmm6[8],xmm2[8],xmm6[9],xmm2[9],xmm6[10],xmm2[10],xmm6[11],xmm2[11],xmm6[12],xmm2[12],xmm6[13],xmm2[13],xmm6[14],xmm2[14],xmm6[15],xmm2[15]
	LONG $0x487df262; WORD $0xf731 // vpmovzxbd	%xmm7, %zmm6    # zmm6 = xmm7[0],zero,zero,zero,xmm7[1],zero,zero,zero,xmm7[2],zero,zero,zero,xmm7[3],zero,zero,zero,xmm7[4],zero,zero,zero,xmm7[5],zero,zero,zero,xmm7[6],zero,zero,zero,xmm7[7],zero,zero,zero,xmm7[8],zero,zero,zero,xmm7[9],zero,zero,zero,xmm7[10],zero,zero,zero,xmm7[11],zero,zero,zero,xmm7[12],zero,zero,zero,xmm7[13],zero,zero,zero,xmm7[14],zero,zero,zero,xmm7[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xf65b // vcvtdq2ps	%zmm6, %zmm6
	LONG $0x487df262; WORD $0xd231 // vpmovzxbd	%xmm2, %zmm2    # zmm2 = xmm2[0],zero,zero,zero,xmm2[1],zero,zero,zero,xmm2[2],zero,zero,zero,xmm2[3],zero,zero,zero,xmm2[4],zero,zero,zero,xmm2[5],zero,zero,zero,xmm2[6],zero,zero,zero,xmm2[7],zero,zero,zero,xmm2[8],zero,zero,zero,xmm2[9],zero,zero,zero,xmm2[10],zero,zero,zero,xmm2[11],zero,zero,zero,xmm2[12],zero,zero,zero,xmm2[13],zero,zero,zero,xmm2[14],zero,zero,zero,xmm2[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xd25b // vcvtdq2ps	%zmm2, %zmm2
	LONG $0xd371c1c5; BYTE $0x04 // vpsrlw	$0x4, %xmm3, %xmm7
	LONG $0xf9dbc1c5 // vpand	%xmm1, %xmm7, %xmm7
	LONG $0xd9dbe1c5 // vpand	%xmm1, %xmm3, %xmm3
	LONG $0xc36041c5 // vpunpcklbw	%xmm3, %xmm7, %xmm8 # xmm8 = xmm7[0],xmm3[0],xmm7[1],xmm3[1],xmm7[2],xmm3[2],xmm7[3],xmm3[3],xmm7[4],xmm3[4],xmm7[5],xmm3[5],xmm7[6],xmm3[6],xmm7[7],xmm3[7]
	LONG $0xdb68c1c5 // vpunpckhbw	%xmm3, %xmm7, %xmm3 # xmm3 = xmm7[8],xmm3[8],xmm7[9],xmm3[9],xmm7[10],xmm3[10],xmm7[11],xmm3[11],xmm7[12],xmm3[12],xmm7[13],xmm3[13],xmm7[14],xmm3[14],xmm7[15],xmm3[15]
	LONG $0x487dd262; WORD $0xf831 // vpmovzxbd	%xmm8, %zmm7    # zmm7 = xmm8[0],zero,zero,zero,xmm8[1],zero,zero,zero,xmm8[2],zero,zero,zero,xmm8[3],zero,zero,zero,xmm8[4],zero,zero,zero,xmm8[5],zero,zero,zero,xmm8[6],zero,zero,zero,xmm8[7],zero,zero,zero,xmm8[8],zero,zero,zero,xmm8[9],zero,zero,zero,xmm8[10],zero,zero,zero,xmm8[11],zero,zero,zero,xmm8[12],zero,zero,zero,xmm8[13],zero,zero,zero,xmm8[14],zero,zero,zero,xmm8[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xff5b // vcvtdq2ps	%zmm7, %zmm7
	LONG $0x487df262; WORD $0xdb31 // vpmovzxbd	%xmm3, %zmm3    # zmm3 = xmm3[0],zero,zero,zero,xmm3[1],zero,zero,zero,xmm3[2],zero,zero,zero,xmm3[3],zero,zero,zero,xmm3[4],zero,zero,zero,xmm3[5],zero,zero,zero,xmm3[6],zero,zero,zero,xmm3[7],zero,zero,zero,xmm3[8],zero,zero,zero,xmm3[9],zero,zero,zero,xmm3[10],zero,zero,zero,xmm3[11],zero,zero,zero,xmm3[12],zero,zero,zero,xmm3[13],zero,zero,zero,xmm3[14],zero,zero,zero,xmm3[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xdb5b // vcvtdq2ps	%zmm3, %zmm3
	LONG $0x487cf162; WORD $0xf659 // vmulps	%zmm6, %zmm0, %zmm6
	LONG $0x487c5162; WORD $0x0410; BYTE $0x80 // vmovups	(%r8,%rax,4), %zmm8
	QUAD $0x01804c10487c5162 // vmovups	0x40(%r8,%rax,4), %zmm9
	LONG $0x484d7262; WORD $0x04a8; BYTE $0x81 // vfmadd213ps	(%rcx,%rax,4), %zmm6, %zmm8 # zmm8 = (zmm6 * zmm8) + mem
	QUAD $0x02807410487cd162 // vmovups	0x80(%r8,%rax,4), %zmm6
	LONG $0x487cf162; WORD $0xd259 // vmulps	%zmm2, %zmm0, %zmm2
	QUAD $0x018154a84835f262 // vfmadd213ps	0x40(%rcx,%rax,4), %zmm9, %zmm2 # zmm2 = (zmm9 * zmm2) + mem
	QUAD $0x03804c10487c5162 // vmovups	0xc0(%r8,%rax,4), %zmm9
	LONG $0x487cf162; WORD $0xff59 // vmulps	%zmm7, %zmm0, %zmm7
	QUAD $0x02817ca8484df262 // vfmadd213ps	0x80(%rcx,%rax,4), %zmm6, %zmm7 # zmm7 = (zmm6 * zmm7) + mem
	LONG $0x487cf162; WORD $0xf359 // vmulps	%zmm3, %zmm0, %zmm6
	QUAD $0x038174a84835f262 // vfmadd213ps	0xc0(%rcx,%rax,4), %zmm9, %zmm6 # zmm6 = (zmm9 * zmm6) + mem
	LONG $0x487cf162; WORD $0x1c10; BYTE $0x87 // vmovups	(%rdi,%rax,4), %zmm3
	LONG $0x4864d162; WORD $0xd85c // vsubps	%zmm8, %zmm3, %zmm3
	QUAD $0x01874410487c7162 // vmovups	0x40(%rdi,%rax,4), %zmm8
	LONG $0x483c7162; WORD $0xc25c // vsubps	%zmm2, %zmm8, %zmm8
	QUAD $0x02875410487cf162 // vmovups	0x80(%rdi,%rax,4), %zmm2
	LONG $0x486cf162; WORD $0xd75c // vsubps	%zmm7, %zmm2, %zmm2
	QUAD $0x03877c10487cf162 // vmovups	0xc0(%rdi,%rax,4), %zmm7
	LONG $0x4844f162; WORD $0xf65c // vsubps	%zmm6, %zmm7, %zmm6
	LONG $0x4865f262; WORD $0xdca8 // vfmadd213ps	%zmm4, %zmm3, %zmm3 # zmm3 = (zmm3 * zmm3) + zmm4
	LONG $0x483dd262; WORD $0xd8b8 // vfmadd231ps	%zmm8, %zmm8, %zmm3 # zmm3 = (zmm8 * zmm8) + zmm3
	LONG $0x486df262; WORD $0xd5a8 // vfmadd213ps	%zmm5, %zmm2, %zmm2 # zmm2 = (zmm2 * zmm2) + zmm5
	LONG $0x484df262; WORD $0xd6b8 // vfmadd231ps	%zmm6, %zmm6, %zmm2 # zmm2 = (zmm6 * zmm6) + zmm2
	LONG $0x40c08348 // addq	$0x40, %rax
	LONG $0x20c38349 // addq	$0x20, %r11
	LONG $0x487cf162; WORD $0xe328 // vmovaps	%zmm3, %zmm4
	LONG $0x487cf162; WORD $0xea28 // vmovaps	%zmm2, %zmm5
	WORD $0x394c; BYTE $0xd0 // cmpq	%r10, %rax
	LONG $0xfec98e0f; WORD $0xffff // jle	0x50 <int4L2DistanceAvx512+0x50>
LBB0_2:
	LONG $0xe0528d4c // leaq	-0x20(%rdx), %r10
	WORD $0x394c; BYTE $0xd0 // cmpq	%r10, %rax
	WORD $0x0b7e // jle	0x19b <int4L2DistanceAvx512+0x19b>
	LONG $0x487cf162; WORD $0xe328 // vmovaps	%zmm3, %zmm4
	LONG $0x0000afe9; BYTE $0x00 // jmp	0x24a <int4L2DistanceAvx512+0x24a>
LBB0_6:
	WORD $0x8949; BYTE $0xc3 // movq	%rax, %r11
	WORD $0xd149; BYTE $0xeb // shrq	%r11
	WORD $0x0149; BYTE $0xf3 // addq	%rsi, %r11
LBB0_7:
	LONG $0x6f7ac1c4; BYTE $0x23 // vmovdqu	(%r11), %xmm4
	LONG $0xd471d1c5; BYTE $0x04 // vpsrlw	$0x4, %xmm4, %xmm5
	LONG $0xe9dbd1c5 // vpand	%xmm1, %xmm5, %xmm5
	LONG $0xe1dbd9c5 // vpand	%xmm1, %xmm4, %xmm4
	LONG $0xf460d1c5 // vpunpcklbw	%xmm4, %xmm5, %xmm6 # xmm6 = xmm5[0],xmm4[0],xmm5[1],xmm4[1],xmm5[2],xmm4[2],xmm5[3],xmm4[3],xmm5[4],xmm4[4],xmm5[5],xmm4[5],xmm5[6],xmm4[6],xmm5[7],xmm4[7]
	LONG $0xe468d1c5 // vpunpckhbw	%xmm4, %xmm5, %xmm4 # xmm4 = xmm5[8],xmm4[8],xmm5[9],xmm4[9],xmm5[10],xmm4[10],xmm5[11],xmm4[11],xmm5[12],xmm4[12],xmm5[13],xmm4[13],xmm5[14],xmm4[14],xmm5[15],xmm4[15]
	LONG $0x487df262; WORD $0xee31 // vpmovzxbd	%xmm6, %zmm5    # zmm5 = xmm6[0],zero,zero,zero,xmm6[1],zero,zero,zero,xmm6[2],zero,zero,zero,xmm6[3],zero,zero,zero,xmm6[4],zero,zero,zero,xmm6[5],zero,zero,zero,xmm6[6],zero,zero,zero,xmm6[7],zero,zero,zero,xmm6[8],zero,zero,zero,xmm6[9],zero,zero,zero,xmm6[10],zero,zero,zero,xmm6[11],zero,zero,zero,xmm6[12],zero,zero,zero,xmm6[13],zero,zero,zero,xmm6[14],zero,zero,zero,xmm6[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xed5b // vcvtdq2ps	%zmm5, %zmm5
	LONG $0x487df262; WORD $0xe431 // vpmovzxbd	%xmm4, %zmm4    # zmm4 = xmm4[0],zero,zero,zero,xmm4[1],zero,zero,zero,xmm4[2],zero,zero,zero,xmm4[3],zero,zero,zero,xmm4[4],zero,zero,zero,xmm4[5],zero,zero,zero,xmm4[6],zero,zero,zero,xmm4[7],zero,zero,zero,xmm4[8],zero,zero,zero,xmm4[9],zero,zero,zero,xmm4[10],zero,zero,zero,xmm4[11],zero,zero,zero,xmm4[12],zero,zero,zero,xmm4[13],zero,zero,zero,xmm4[14],zero,zero,zero,xmm4[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xe45b // vcvtdq2ps	%zmm4, %zmm4
	LONG $0x487cf162; WORD $0xed59 // vmulps	%zmm5, %zmm0, %zmm5
	LONG $0x487cd162; WORD $0x3410; BYTE $0x80 // vmovups	(%r8,%rax,4), %zmm6
	QUAD $0x01807c10487cd162 // vmovups	0x40(%r8,%rax,4), %zmm7
	LONG $0x4855f262; WORD $0x34a8; BYTE $0x81 // vfmadd213ps	(%rcx,%rax,4), %zmm5, %zmm6 # zmm6 = (zmm5 * zmm6) + mem
	LONG $0x487cf162; WORD $0xec59 // vmulps	%zmm4, %zmm0, %zmm5
	QUAD $0x01816ca84845f262 // vfmadd213ps	0x40(%rcx,%rax,4), %zmm7, %zmm5 # zmm5 = (zmm7 * zmm5) + mem
	LONG $0x487cf162; WORD $0x2410; BYTE $0x87 // vmovups	(%rdi,%rax,4), %zmm4
	LONG $0x485cf162; WORD $0xe65c // vsubps	%zmm6, %zmm4, %zmm4
	QUAD $0x01877410487cf162 // vmovups	0x40(%rdi,%rax,4), %zmm6
	LONG $0x484cf162; WORD $0xed5c // vsubps	%zmm5, %zmm6, %zmm5
	LONG $0x485df262; WORD $0xe3a8 // vfmadd213ps	%zmm3, %zmm4, %zmm4 # zmm4 = (zmm4 * zmm4) + zmm3
	LONG $0x4855f262; WORD $0xe5b8 // vfmadd231ps	%zmm5, %zmm5, %zmm4 # zmm4 = (zmm5 * zmm5) + zmm4
	LONG $0x20c08348 // addq	$0x20, %rax
	LONG $0x10c38349 // addq	$0x10, %r11
	LONG $0x487cf162; WORD $0xdc28 // vmovaps	%zmm4, %zmm3
	WORD $0x394c; BYTE $0xd0 // cmpq	%r10, %rax
	LONG $0xff668e0f; WORD $0xffff // jle	0x1b0 <int4L2DistanceAvx512+0x1b0>
LBB0_8:
	LONG $0x486cf162; WORD $0xc458 // vaddps	%zmm4, %zmm2, %zmm0
	LONG $0x48fdf362; WORD $0xc11b; BYTE $0x01 // vextractf64x4	$0x1, %zmm0, %ymm1
	LONG $0x487cf162; WORD $0xc158 // vaddps	%zmm1, %zmm0, %zmm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc8c6f9c5; BYTE $0x01 // vshufpd	$0x1, %xmm0, %xmm0, %xmm1 # xmm1 = xmm0[1,0]
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc816fac5 // vmovshdup	%xmm0, %xmm1    # xmm1 = xmm0[1,1,3,3]
	LONG $0xd158fac5 // vaddss	%xmm1, %xmm0, %xmm2
	LONG $0x8889ba41; WORD $0x3d88 // movl	$0x3d888889, %r10d      # imm = 0x3D888889
	LONG $0x6e7941c4; BYTE $0xfa // vmovd	%r10d, %xmm15
	LONG $0x3c117ac5; BYTE $0x24 // vmovss	%xmm15, (%rsp)
	WORD $0x3948; BYTE $0xd0 // cmpq	%rdx, %rax
	LONG $0x009a8d0f; WORD $0x0000 // jge	0x32b <int4L2DistanceAvx512+0x32b>
	LONG $0x0410fac5; BYTE $0x24 // vmovss	(%rsp), %xmm0
	WORD $0x8949; BYTE $0xc2 // movq	%rax, %r10
	WORD $0xd149; BYTE $0xea // shrq	%r10
	WORD $0x014c; BYTE $0xd6 // addq	%r10, %rsi
	WORD $0x1feb // jmp	0x2c0 <int4L2DistanceAvx512+0x2c0>
LBB0_13:
	LONG $0x02c08348 // addq	$0x2, %rax
	WORD $0xff48; BYTE $0xc6 // incq	%rsi
	LONG $0xd128f8c5 // vmovaps	%xmm1, %xmm2
	WORD $0x3948; BYTE $0xd0 // cmpq	%rdx, %rax
	WORD $0x6f7d // jge	0x32f <int4L2DistanceAvx512+0x32f>
LBB0_11:
	LONG $0x16b60f44 // movzbl	(%rsi), %r10d
	WORD $0x8945; BYTE $0xd3 // movl	%r10d, %r11d
	LONG $0x04ebc041 // shrb	$0x4, %r11b
	LONG $0xdbb60f45 // movzbl	%r11b, %r11d
	LONG $0x2a2ac1c4; BYTE $0xcb // vcvtsi2ss	%r11d, %xmm10, %xmm1
	LONG $0xc959fac5 // vmulss	%xmm1, %xmm0, %xmm1
	LONG $0x107ac1c4; WORD $0x801c // vmovss	(%r8,%rax,4), %xmm3
	LONG $0xa971e2c4; WORD $0x811c // vfmadd213ss	(%rcx,%rax,4), %xmm1, %xmm3 # xmm3 = (xmm1 * xmm3) + mem
	LONG $0x0c10fac5; BYTE $0x87 // vmovss	(%rdi,%rax,4), %xmm1
	LONG $0xcb5cf2c5 // vsubss	%xmm3, %xmm1, %xmm1
	LONG $0xa971e2c4; BYTE $0xca // vfmadd213ss	%xmm2, %xmm1, %xmm1 # xmm1 = (xmm1 * xmm1) + xmm2
	LONG $0x01588d4c // leaq	0x1(%rax), %r11
	WORD $0x3949; BYTE $0xd3 // cmpq	%rdx, %r11
	WORD $0xb57d // jge	0x2b0 <int4L2DistanceAvx512+0x2b0>
	LONG $0x0fe28041 // andb	$0xf, %r10b
	LONG $0xd2b60f45 // movzbl	%r10b, %r10d
	LONG $0x2a2ac1c4; BYTE $0xd2 // vcvtsi2ss	%r10d, %xmm10, %xmm2
	LONG $0xd259fac5 // vmulss	%xmm2, %xmm0, %xmm2
	LONG $0x107ac1c4; WORD $0x805c; BYTE $0x04 // vmovss	0x4(%r8,%rax,4), %xmm3
	LONG $0xa969e2c4; WORD $0x815c; BYTE $0x04 // vfmadd213ss	0x4(%rcx,%rax,4), %xmm2, %xmm3 # xmm3 = (xmm2 * xmm3) + mem
	LONG $0x5410fac5; WORD $0x0487 // vmovss	0x4(%rdi,%rax,4), %xmm2
	LONG $0xd35ceac5 // vsubss	%xmm3, %xmm2, %xmm2
	LONG $0xb969e2c4; BYTE $0xca // vfmadd231ss	%xmm2, %xmm2, %xmm1 # xmm1 = (xmm2 * xmm2) + xmm1
	WORD $0x85eb // jmp	0x2b0 <int4L2DistanceAvx512+0x2b0>
LBB0_9:
	LONG $0xca28f8c5 // vmovaps	%xmm2, %xmm1
LBB0_14:
	LONG $0x117ac1c4; BYTE $0x09 // vmovss	%xmm1, (%r9)
	LONG $0x04c48348 // addq	$0x4, %rsp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT ·int4L2DistanceBatchAvx512(SB), NOSPLIT, $0-56
	MOVQ query+0(FP), DI
	MOVQ codes+8(FP), SI
	MOVQ dim+16(FP), DX
	MOVQ n+24(FP), CX
	MOVQ minVal+32(FP), R8
	MOVQ diff+40(FP), R9

	BYTE $0x55 // pushq	%rbp
	WORD $0x5741 // pushq	%r15
	WORD $0x5641 // pushq	%r14
	WORD $0x5541 // pushq	%r13
	WORD $0x5441 // pushq	%r12
	BYTE $0x53 // pushq	%rbx
	LONG $0x20ec8348 // subq	$0x20, %rsp
	LONG $0x24748948; BYTE $0x08 // movq	%rsi, 0x8(%rsp)
	LONG $0x888889b8; BYTE $0x3d // movl	$0x3d888889, %eax       # imm = 0x3D888889
	LONG $0xc06ef9c5 // vmovd	%eax, %xmm0
	LONG $0x0f0f0fb8; BYTE $0x0f // movl	$0xf0f0f0f, %eax        # imm = 0xF0F0F0F
	LONG $0xc86ef9c5 // vmovd	%eax, %xmm1
	LONG $0x888889b8; BYTE $0x3d // movl	$0x3d888889, %eax       # imm = 0x3D888889
	LONG $0xf86e79c5 // vmovd	%eax, %xmm15
	LONG $0x7c117ac5; WORD $0x0424 // vmovss	%xmm15, 0x4(%rsp)
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	LONG $0x03728e0f; WORD $0x0000 // jle	0x9cf <int4L2DistanceBatchAvx512+0x3af>
	LONG $0x01428d48 // leaq	0x1(%rdx), %rax
	LONG $0x3fe8c148 // shrq	$0x3f, %rax
	WORD $0x0148; BYTE $0xd0 // addq	%rdx, %rax
	WORD $0xff48; BYTE $0xc0 // incq	%rax
	WORD $0xd148; BYTE $0xf8 // sarq	%rax
	LONG $0x24448948; BYTE $0x10 // movq	%rax, 0x10(%rsp)
	LONG $0x487df262; WORD $0xc018 // vbroadcastss	%xmm0, %zmm0
	LONG $0x5879e2c4; BYTE $0xc9 // vpbroadcastd	%xmm1, %xmm1
	LONG $0xc05a8d4c // leaq	-0x40(%rdx), %r11
	LONG $0xe05a8d48 // leaq	-0x20(%rdx), %rbx
	LONG $0x5410fac5; WORD $0x0424 // vmovss	0x4(%rsp), %xmm2
	WORD $0x894c; BYTE $0xd8 // movq	%r11, %rax
	LONG $0xc0e08348 // andq	$-0x40, %rax
	LONG $0x40c08348 // addq	$0x40, %rax
	LONG $0x24448948; BYTE $0x18 // movq	%rax, 0x18(%rsp)
	LONG $0x24648b4c; BYTE $0x08 // movq	0x8(%rsp), %r12
	LONG $0x247c8d4d; BYTE $0x10 // leaq	0x10(%r12), %r15
	WORD $0x3145; BYTE $0xed // xorl	%r13d, %r13d
	WORD $0x2beb // jmp	0x6d6 <int4L2DistanceBatchAvx512+0xb6>
LBB2_14:
	LONG $0xdc28f8c5 // vmovaps	%xmm4, %xmm3
LBB2_19:
	LONG $0x24448b48; BYTE $0x58 // movq	0x58(%rsp), %rax
	LONG $0x117aa1c4; WORD $0xa81c // vmovss	%xmm3, (%rax,%r13,4)
	LONG $0x24448b48; BYTE $0x10 // movq	0x10(%rsp), %rax
	WORD $0x0149; BYTE $0xc7 // addq	%rax, %r15
	WORD $0x0149; BYTE $0xc4 // addq	%rax, %r12
	WORD $0x8949; BYTE $0xed // movq	%rbp, %r13
	WORD $0x3948; BYTE $0xcd // cmpq	%rcx, %rbp
	LONG $0x02f9840f; WORD $0x0000 // je	0x9cf <int4L2DistanceBatchAvx512+0x3af>
LBB2_2:
	LONG $0x016d8d49 // leaq	0x1(%r13), %rbp
	WORD $0x3948; BYTE $0xcd // cmpq	%rcx, %rbp
	WORD $0x127d // jge	0x6f1 <int4L2DistanceBatchAvx512+0xd1>
	WORD $0x8948; BYTE $0xe8 // movq	%rbp, %rax
	LONG $0x44af0f48; WORD $0x1024 // imulq	0x10(%rsp), %rax
	LONG $0x24748b48; BYTE $0x08 // movq	0x8(%rsp), %rsi
	LONG $0x060c180f // prefetcht0	(%rsi,%rax)
LBB2_4:
	LONG $0x40fa8348 // cmpq	$0x40, %rdx
	LONG $0x00c58d0f; WORD $0x0000 // jge	0x7c0 <int4L2DistanceBatchAvx512+0x1a0>
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	LONG $0xe457d8c5 // vxorps	%xmm4, %xmm4, %xmm4
	WORD $0x3949; BYTE $0xde // cmpq	%rbx, %r14
	LONG $0x01ea8f0f; WORD $0x0000 // jg	0x8f9 <int4L2DistanceBatchAvx512+0x2d9>
LBB2_11:
	WORD $0x894c; BYTE $0xf0 // movq	%r14, %rax
	WORD $0xd148; BYTE $0xe8 // shrq	%rax
	WORD $0x014c; BYTE $0xe0 // addq	%r12, %rax
LBB2_12:
	LONG $0x286ffac5 // vmovdqu	(%rax), %xmm5
	LONG $0xd571c9c5; BYTE $0x04 // vpsrlw	$0x4, %xmm5, %xmm6
	LONG $0xf1dbc9c5 // vpand	%xmm1, %xmm6, %xmm6
	LONG $0xe9dbd1c5 // vpand	%xmm1, %xmm5, %xmm5
	LONG $0xfd60c9c5 // vpunpcklbw	%xmm5, %xmm6, %xmm7 # xmm7 = xmm6[0],xmm5[0],xmm6[1],xmm5[1],xmm6[2],xmm5[2],xmm6[3],xmm5[3],xmm6[4],xmm5[4],xmm6[5],xmm5[5],xmm6[6],xmm5[6],xmm6[7],xmm5[7]
	LONG $0x487df262; WORD $0xff31 // vpmovzxbd	%xmm7, %zmm7    # zmm7 = xmm7[0],zero,zero,zero,xmm7[1],zero,zero,zero,xmm7[2],zero,zero,zero,xmm7[3],zero,zero,zero,xmm7[4],zero,zero,zero,xmm7[5],zero,zero,zero,xmm7[6],zero,zero,zero,xmm7[7],zero,zero,zero,xmm7[8],zero,zero,zero,xmm7[9],zero,zero,zero,xmm7[10],zero,zero,zero,xmm7[11],zero,zero,zero,xmm7[12],zero,zero,zero,xmm7[13],zero,zero,zero,xmm7[14],zero,zero,zero,xmm7[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xff5b // vcvtdq2ps	%zmm7, %zmm7
	LONG $0xed68c9c5 // vpunpckhbw	%xmm5, %xmm6, %xmm5 # xmm5 = xmm6[8],xmm5[8],xmm6[9],xmm5[9],xmm6[10],xmm5[10],xmm6[11],xmm5[11],xmm6[12],xmm5[12],xmm6[13],xmm5[13],xmm6[14],xmm5[14],xmm6[15],xmm5[15]
	LONG $0x487df262; WORD $0xed31 // vpmovzxbd	%xmm5, %zmm5    # zmm5 = xmm5[0],zero,zero,zero,xmm5[1],zero,zero,zero,xmm5[2],zero,zero,zero,xmm5[3],zero,zero,zero,xmm5[4],zero,zero,zero,xmm5[5],zero,zero,zero,xmm5[6],zero,zero,zero,xmm5[7],zero,zero,zero,xmm5[8],zero,zero,zero,xmm5[9],zero,zero,zero,xmm5[10],zero,zero,zero,xmm5[11],zero,zero,zero,xmm5[12],zero,zero,zero,xmm5[13],zero,zero,zero,xmm5[14],zero,zero,zero,xmm5[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xed5b // vcvtdq2ps	%zmm5, %zmm5
	LONG $0x487cf162; WORD $0xf759 // vmulps	%zmm7, %zmm0, %zmm6
	LONG $0x487c9162; WORD $0x3c10; BYTE $0xb1 // vmovups	(%r9,%r14,4), %zmm7
	QUAD $0x01b14410487c1162 // vmovups	0x40(%r9,%r14,4), %zmm8
	LONG $0x484d9262; WORD $0x3ca8; BYTE $0xb0 // vfmadd213ps	(%r8,%r14,4), %zmm6, %zmm7 # zmm7 = (zmm6 * zmm7) + mem
	LONG $0x487cf162; WORD $0xf559 // vmulps	%zmm5, %zmm0, %zmm6
	QUAD $0x01b074a8483d9262 // vfmadd213ps	0x40(%r8,%r14,4), %zmm8, %zmm6 # zmm6 = (zmm8 * zmm6) + mem
	LONG $0x487cb162; WORD $0x2c10; BYTE $0xb7 // vmovups	(%rdi,%r14,4), %zmm5
	LONG $0x4854f162; WORD $0xef5c // vsubps	%zmm7, %zmm5, %zmm5
	QUAD $0x01b77c10487cb162 // vmovups	0x40(%rdi,%r14,4), %zmm7
	LONG $0x4844f162; WORD $0xf65c // vsubps	%zmm6, %zmm7, %zmm6
	LONG $0x4855f262; WORD $0xeca8 // vfmadd213ps	%zmm4, %zmm5, %zmm5 # zmm5 = (zmm5 * zmm5) + zmm4
	LONG $0x484df262; WORD $0xeeb8 // vfmadd231ps	%zmm6, %zmm6, %zmm5 # zmm5 = (zmm6 * zmm6) + zmm5
	LONG $0x20c68349 // addq	$0x20, %r14
	LONG $0x10c08348 // addq	$0x10, %rax
	LONG $0x487cf162; WORD $0xe528 // vmovaps	%zmm5, %zmm4
	WORD $0x3949; BYTE $0xde // cmpq	%rbx, %r14
	LONG $0xff678e0f; WORD $0xffff // jle	0x720 <int4L2DistanceBatchAvx512+0x100>
	LONG $0x000141e9; BYTE $0x00 // jmp	0x8ff <int4L2DistanceBatchAvx512+0x2df>
LBB2_8:
	LONG $0xe457d8c5 // vxorps	%xmm4, %xmm4, %xmm4
	WORD $0x894d; BYTE $0xfe // movq	%r15, %r14
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	WORD $0xc031 // xorl	%eax, %eax
LBB2_9:
	LONG $0x6f7ac1c4; WORD $0xf06e // vmovdqu	-0x10(%r14), %xmm5
	LONG $0x6f7ac1c4; BYTE $0x36 // vmovdqu	(%r14), %xmm6
	LONG $0xd571c1c5; BYTE $0x04 // vpsrlw	$0x4, %xmm5, %xmm7
	LONG $0xf9dbc1c5 // vpand	%xmm1, %xmm7, %xmm7
	LONG $0xe9dbd1c5 // vpand	%xmm1, %xmm5, %xmm5
	LONG $0xc56041c5 // vpunpcklbw	%xmm5, %xmm7, %xmm8 # xmm8 = xmm7[0],xmm5[0],xmm7[1],xmm5[1],xmm7[2],xmm5[2],xmm7[3],xmm5[3],xmm7[4],xmm5[4],xmm7[5],xmm5[5],xmm7[6],xmm5[6],xmm7[7],xmm5[7]
	LONG $0x487d5262; WORD $0xc031 // vpmovzxbd	%xmm8, %zmm8    # zmm8 = xmm8[0],zero,zero,zero,xmm8[1],zero,zero,zero,xmm8[2],zero,zero,zero,xmm8[3],zero,zero,zero,xmm8[4],zero,zero,zero,xmm8[5],zero,zero,zero,xmm8[6],zero,zero,zero,xmm8[7],zero,zero,zero,xmm8[8],zero,zero,zero,xmm8[9],zero,zero,zero,xmm8[10],zero,zero,zero,xmm8[11],zero,zero,zero,xmm8[12],zero,zero,zero,xmm8[13],zero,zero,zero,xmm8[14],zero,zero,zero,xmm8[15],zero,zero,zero
	LONG $0x487c5162; WORD $0xc05b // vcvtdq2ps	%zmm8, %zmm8
	LONG $0xed68c1c5 // vpunpckhbw	%xmm5, %xmm7, %xmm5 # xmm5 = xmm7[8],xmm5[8],xmm7[9],xmm5[9],xmm7[10],xmm5[10],xmm7[11],xmm5[11],xmm7[12],xmm5[12],xmm7[13],xmm5[13],xmm7[14],xmm5[14],xmm7[15],xmm5[15]
	LONG $0x487df262; WORD $0xed31 // vpmovzxbd	%xmm5, %zmm5    # zmm5 = xmm5[0],zero,zero,zero,xmm5[1],zero,zero,zero,xmm5[2],zero,zero,zero,xmm5[3],zero,zero,zero,xmm5[4],zero,zero,zero,xmm5[5],zero,zero,zero,xmm5[6],zero,zero,zero,xmm5[7],zero,zero,zero,xmm5[8],zero,zero,zero,xmm5[9],zero,zero,zero,xmm5[10],zero,zero,zero,xmm5[11],zero,zero,zero,xmm5[12],zero,zero,zero,xmm5[13],zero,zero,zero,xmm5[14],zero,zero,zero,xmm5[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xed5b // vcvtdq2ps	%zmm5, %zmm5
	LONG $0xd671c1c5; BYTE $0x04 // vpsrlw	$0x4, %xmm6, %xmm7
	LONG $0xf9dbc1c5 // vpand	%xmm1, %xmm7, %xmm7
	LONG $0xf1dbc9c5 // vpand	%xmm1, %xmm6, %xmm6
	LONG $0xce6041c5 // vpunpcklbw	%xmm6, %xmm7, %xmm9 # xmm9 = xmm7[0],xmm6[0],xmm7[1],xmm6[1],xmm7[2],xmm6[2],xmm7[3],xmm6[3],xmm7[4],xmm6[4],xmm7[5],xmm6[5],xmm7[6],xmm6[6],xmm7[7],xmm6[7]
	LONG $0x487d5262; WORD $0xc931 // vpmovzxbd	%xmm9, %zmm9    # zmm9 = xmm9[0],zero,zero,zero,xmm9[1],zero,zero,zero,xmm9[2],zero,zero,zero,xmm9[3],zero,zero,zero,xmm9[4],zero,zero,zero,xmm9[5],zero,zero,zero,xmm9[6],zero,zero,zero,xmm9[7],zero,zero,zero,xmm9[8],zero,zero,zero,xmm9[9],zero,zero,zero,xmm9[10],zero,zero,zero,xmm9[11],zero,zero,zero,xmm9[12],zero,zero,zero,xmm9[13],zero,zero,zero,xmm9[14],zero,zero,zero,xmm9[15],zero,zero,zero
	LONG $0x487c5162; WORD $0xc95b // vcvtdq2ps	%zmm9, %zmm9
	LONG $0xf668c1c5 // vpunpckhbw	%xmm6, %xmm7, %xmm6 # xmm6 = xmm7[8],xmm6[8],xmm7[9],xmm6[9],xmm7[10],xmm6[10],xmm7[11],xmm6[11],xmm7[12],xmm6[12],xmm7[13],xmm6[13],xmm7[14],xmm6[14],xmm7[15],xmm6[15]
	LONG $0x487df262; WORD $0xf631 // vpmovzxbd	%xmm6, %zmm6    # zmm6 = xmm6[0],zero,zero,zero,xmm6[1],zero,zero,zero,xmm6[2],zero,zero,zero,xmm6[3],zero,zero,zero,xmm6[4],zero,zero,zero,xmm6[5],zero,zero,zero,xmm6[6],zero,zero,zero,xmm6[7],zero,zero,zero,xmm6[8],zero,zero,zero,xmm6[9],zero,zero,zero,xmm6[10],zero,zero,zero,xmm6[11],zero,zero,zero,xmm6[12],zero,zero,zero,xmm6[13],zero,zero,zero,xmm6[14],zero,zero,zero,xmm6[15],zero,zero,zero
	LONG $0x487cf162; WORD $0xf65b // vcvtdq2ps	%zmm6, %zmm6
	LONG $0x487cd162; WORD $0xf859 // vmulps	%zmm8, %zmm0, %zmm7
	LONG $0x487c5162; WORD $0x0410; BYTE $0x81 // vmovups	(%r9,%rax,4), %zmm8
	LONG $0x48455262; WORD $0x04a8; BYTE $0x80 // vfmadd213ps	(%r8,%rax,4), %zmm7, %zmm8 # zmm8 = (zmm7 * zmm8) + mem
	QUAD $0x01817c10487cd162 // vmovups	0x40(%r9,%rax,4), %zmm7
	LONG $0x487cf162; WORD $0xed59 // vmulps	%zmm5, %zmm0, %zmm5
	QUAD $0x01806ca84845d262 // vfmadd213ps	0x40(%r8,%rax,4), %zmm7, %zmm5 # zmm5 = (zmm7 * zmm5) + mem
	QUAD $0x02817c10487cd162 // vmovups	0x80(%r9,%rax,4), %zmm7
	LONG $0x487c5162; WORD $0xc959 // vmulps	%zmm9, %zmm0, %zmm9
	QUAD $0x02804ca848455262 // vfmadd213ps	0x80(%r8,%rax,4), %zmm7, %zmm9 # zmm9 = (zmm7 * zmm9) + mem
	QUAD $0x03817c10487cd162 // vmovups	0xc0(%r9,%rax,4), %zmm7
	LONG $0x487cf162; WORD $0xf659 // vmulps	%zmm6, %zmm0, %zmm6
	QUAD $0x038074a84845d262 // vfmadd213ps	0xc0(%r8,%rax,4), %zmm7, %zmm6 # zmm6 = (zmm7 * zmm6) + mem
	LONG $0x487cf162; WORD $0x3c10; BYTE $0x87 // vmovups	(%rdi,%rax,4), %zmm7
	LONG $0x4844d162; WORD $0xf85c // vsubps	%zmm8, %zmm7, %zmm7
	QUAD $0x01874410487c7162 // vmovups	0x40(%rdi,%rax,4), %zmm8
	LONG $0x483cf162; WORD $0xed5c // vsubps	%zmm5, %zmm8, %zmm5
	QUAD $0x02874410487c7162 // vmovups	0x80(%rdi,%rax,4), %zmm8
	LONG $0x483c5162; WORD $0xc15c // vsubps	%zmm9, %zmm8, %zmm8
	QUAD $0x03874c10487c7162 // vmovups	0xc0(%rdi,%rax,4), %zmm9
	LONG $0x4834f162; WORD $0xf65c // vsubps	%zmm6, %zmm9, %zmm6
	LONG $0x4845f262; WORD $0xe7b8 // vfmadd231ps	%zmm7, %zmm7, %zmm4 # zmm4 = (zmm7 * zmm7) + zmm4
	LONG $0x4855f262; WORD $0xe5b8 // vfmadd231ps	%zmm5, %zmm5, %zmm4 # zmm4 = (zmm5 * zmm5) + zmm4
	LONG $0x483dd262; WORD $0xd8b8 // vfmadd231ps	%zmm8, %zmm8, %zmm3 # zmm3 = (zmm8 * zmm8) + zmm3
	LONG $0x484df262; WORD $0xdeb8 // vfmadd231ps	%zmm6, %zmm6, %zmm3 # zmm3 = (zmm6 * zmm6) + zmm3
	LONG $0x40c08348 // addq	$0x40, %rax
	LONG $0x20c68349 // addq	$0x20, %r14
	WORD $0x394c; BYTE $0xd8 // cmpq	%r11, %rax
	LONG $0xfee58e0f; WORD $0xffff // jle	0x7d0 <int4L2DistanceBatchAvx512+0x1b0>
	LONG $0x24748b4c; BYTE $0x18 // movq	0x18(%rsp), %r14
	WORD $0x3949; BYTE $0xde // cmpq	%rbx, %r14
	LONG $0xfe168e0f; WORD $0xffff // jle	0x70f <int4L2DistanceBatchAvx512+0xef>
LBB2_7:
	LONG $0x487cf162; WORD $0xec28 // vmovaps	%zmm4, %zmm5
LBB2_13:
	LONG $0x4864f162; WORD $0xdd58 // vaddps	%zmm5, %zmm3, %zmm3
	LONG $0x48fdf362; WORD $0xdc1b; BYTE $0x01 // vextractf64x4	$0x1, %zmm3, %ymm4
	LONG $0x4864f162; WORD $0xdc58 // vaddps	%zmm4, %zmm3, %zmm3
	LONG $0x197de3c4; WORD $0x01dc // vextractf128	$0x1, %ymm3, %xmm4
	LONG $0xdc58e0c5 // vaddps	%xmm4, %xmm3, %xmm3
	LONG $0xe3c6e1c5; BYTE $0x01 // vshufpd	$0x1, %xmm3, %xmm3, %xmm4 # xmm4 = xmm3[1,0]
	LONG $0xdc58e0c5 // vaddps	%xmm4, %xmm3, %xmm3
	LONG $0xe316fac5 // vmovshdup	%xmm3, %xmm4    # xmm4 = xmm3[1,1,3,3]
	LONG $0xe458e2c5 // vaddss	%xmm4, %xmm3, %xmm4
	WORD $0x3949; BYTE $0xd6 // cmpq	%rdx, %r14
	LONG $0xfd7a8d0f; WORD $0xffff // jge	0x6b0 <int4L2DistanceBatchAvx512+0x90>
	WORD $0x894c; BYTE $0xf0 // movq	%r14, %rax
	WORD $0xd148; BYTE $0xe8 // shrq	%rax
	WORD $0x014c; BYTE $0xe0 // addq	%r12, %rax
	WORD $0x23eb // jmp	0x964 <int4L2DistanceBatchAvx512+0x344>
LBB2_18:
	LONG $0x02c68349 // addq	$0x2, %r14
	WORD $0xff48; BYTE $0xc0 // incq	%rax
	LONG $0xe328f8c5 // vmovaps	%xmm3, %xmm4
	WORD $0x3949; BYTE $0xd6 // cmpq	%rdx, %r14
	LONG $0xfd508d0f; WORD $0xffff // jge	0x6b4 <int4L2DistanceBatchAvx512+0x94>
LBB2_16:
	LONG $0x10b60f44 // movzbl	(%rax), %r10d
	WORD $0x8944; BYTE $0xd6 // movl	%r10d, %esi
	LONG $0x04eec040 // shrb	$0x4, %sil
	LONG $0xf6b60f40 // movzbl	%sil, %esi
	LONG $0xde2aaac5 // vcvtsi2ss	%esi, %xmm10, %xmm3
	LONG $0xdb59eac5 // vmulss	%xmm3, %xmm2, %xmm3
	LONG $0x107a81c4; WORD $0xb12c // vmovss	(%r9,%r14,4), %xmm5
	LONG $0xa96182c4; WORD $0xb02c // vfmadd213ss	(%r8,%r14,4), %xmm3, %xmm5 # xmm5 = (xmm3 * xmm5) + mem
	LONG $0x107aa1c4; WORD $0xb71c // vmovss	(%rdi,%r14,4), %xmm3
	LONG $0xdd5ce2c5 // vsubss	%xmm5, %xmm3, %xmm3
	LONG $0xa961e2c4; BYTE $0xdc // vfmadd213ss	%xmm4, %xmm3, %xmm3 # xmm3 = (xmm3 * xmm3) + xmm4
	LONG $0x01768d49 // leaq	0x1(%r14), %rsi
	WORD $0x3948; BYTE $0xd6 // cmpq	%rdx, %rsi
	WORD $0xb17d // jge	0x950 <int4L2DistanceBatchAvx512+0x330>
	LONG $0x0fe28041 // andb	$0xf, %r10b
	LONG $0xf2b60f41 // movzbl	%r10b, %esi
	LONG $0xe62aaac5 // vcvtsi2ss	%esi, %xmm10, %xmm4
	LONG $0xe459eac5 // vmulss	%xmm4, %xmm2, %xmm4
	LONG $0x107a81c4; WORD $0xb16c; BYTE $0x04 // vmovss	0x4(%r9,%r14,4), %xmm5
	LONG $0xa95982c4; WORD $0xb06c; BYTE $0x04 // vfmadd213ss	0x4(%r8,%r14,4), %xmm4, %xmm5 # xmm5 = (xmm4 * xmm5) + mem
	LONG $0x107aa1c4; WORD $0xb764; BYTE $0x04 // vmovss	0x4(%rdi,%r14,4), %xmm4
	LONG $0xe55cdac5 // vsubss	%xmm5, %xmm4, %xmm4
	LONG $0xb959e2c4; BYTE $0xdc // vfmadd231ss	%xmm4, %xmm4, %xmm3 # xmm3 = (xmm4 * xmm4) + xmm3
	WORD $0x81eb // jmp	0x950 <int4L2DistanceBatchAvx512+0x330>
LBB2_20:
	LONG $0x20c48348 // addq	$0x20, %rsp
	BYTE $0x5b // popq	%rbx
	WORD $0x5c41 // popq	%r12
	WORD $0x5d41 // popq	%r13
	WORD $0x5e41 // popq	%r14
	WORD $0x5f41 // popq	%r15
	BYTE $0x5d // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT ·int4L2DistancePrecomputedAvx512(SB), NOSPLIT, $0-40
	MOVQ query+0(FP), DI
	MOVQ code+8(FP), SI
	MOVQ dim+16(FP), DX
	MOVQ lookupTable+24(FP), CX
	MOVQ out+32(FP), R8

	BYTE $0x55 // pushq	%rbp
	WORD $0x5741 // pushq	%r15
	WORD $0x5641 // pushq	%r14
	WORD $0x5541 // pushq	%r13
	WORD $0x5441 // pushq	%r12
	BYTE $0x53 // pushq	%rbx
	LONG $0x40ec8348 // subq	$0x40, %rsp
	LONG $0x2444894c; BYTE $0x10 // movq	%r8, 0x10(%rsp)
	LONG $0x10fa8348 // cmpq	$0x10, %rdx
	LONG $0x24548948; BYTE $0x08 // movq	%rdx, 0x8(%rsp)
	LONG $0x24348948 // movq	%rsi, (%rsp)
	WORD $0x0b7d // jge	0x36d <int4L2DistancePrecomputedAvx512+0x2d>
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	WORD $0xdb31 // xorl	%ebx, %ebx
	LONG $0x0001ece9; BYTE $0x00 // jmp	0x559 <int4L2DistancePrecomputedAvx512+0x219>
LBB1_2:
	LONG $0xf0428d48 // leaq	-0x10(%rdx), %rax
	LONG $0x24448948; BYTE $0x18 // movq	%rax, 0x18(%rsp)
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x00f0ba41; WORD $0x0000 // movl	$0xf0, %r10d
	WORD $0xdb31 // xorl	%ebx, %ebx
	LONG $0x247c8948; BYTE $0x20 // movq	%rdi, 0x20(%rsp)
LBB1_3:
	LONG $0x24748948; BYTE $0x38 // movq	%rsi, 0x38(%rsp)
	WORD $0x8b4c; BYTE $0x36 // movq	(%rsi), %r14
	WORD $0x8944; BYTE $0xf0 // movl	%r14d, %eax
	LONG $0x24448948; BYTE $0x28 // movq	%rax, 0x28(%rsp)
	LONG $0x24448948; BYTE $0x30 // movq	%rax, 0x30(%rsp)
	WORD $0x8945; BYTE $0xf7 // movl	%r14d, %r15d
	WORD $0x8945; BYTE $0xf4 // movl	%r14d, %r12d
	WORD $0x8945; BYTE $0xf5 // movl	%r14d, %r13d
	WORD $0x8945; BYTE $0xf1 // movl	%r14d, %r9d
	WORD $0x8945; BYTE $0xf0 // movl	%r14d, %r8d
	WORD $0x8945; BYTE $0xf3 // movl	%r14d, %r11d
	WORD $0x894c; BYTE $0xf2 // movq	%r14, %rdx
	WORD $0x894c; BYTE $0xf6 // movq	%r14, %rsi
	WORD $0x894c; BYTE $0xf7 // movq	%r14, %rdi
	WORD $0x894c; BYTE $0xf0 // movq	%r14, %rax
	WORD $0x894c; BYTE $0xf5 // movq	%r14, %rbp
	LONG $0x34edc148 // shrq	$0x34, %rbp
	WORD $0xe583; BYTE $0x0f // andl	$0xf, %ebp
	WORD $0x014c; BYTE $0xd5 // addq	%r10, %rbp
	QUAD $0xffff40a98c10fac5; BYTE $0xff // vmovss	-0xc0(%rcx,%rbp,4), %xmm1
	WORD $0x894c; BYTE $0xf5 // movq	%r14, %rbp
	LONG $0x30edc148 // shrq	$0x30, %rbp
	WORD $0xe583; BYTE $0x0f // andl	$0xf, %ebp
	WORD $0x014c; BYTE $0xd5 // addq	%r10, %rbp
	QUAD $0x1080a94c2171e3c4 // vinsertps	$0x10, -0x80(%rcx,%rbp,4), %xmm1, %xmm1 # xmm1 = xmm1[0],mem[0],xmm1[2,3]
	WORD $0x894c; BYTE $0xf5 // movq	%r14, %rbp
	LONG $0x3ceec149 // shrq	$0x3c, %r14
	WORD $0x014d; BYTE $0xd6 // addq	%r10, %r14
	QUAD $0x20c0b14c2171a3c4 // vinsertps	$0x20, -0x40(%rcx,%r14,4), %xmm1, %xmm1 # xmm1 = xmm1[0,1],mem[0],xmm1[3]
	LONG $0x38edc148 // shrq	$0x38, %rbp
	WORD $0xe583; BYTE $0x0f // andl	$0xf, %ebp
	WORD $0x014c; BYTE $0xd5 // addq	%r10, %rbp
	LONG $0x2171e3c4; WORD $0xa90c; BYTE $0x30 // vinsertps	$0x30, (%rcx,%rbp,4), %xmm1, %xmm1 # xmm1 = xmm1[0,1,2],mem[0]
	LONG $0x24eec148 // shrq	$0x24, %rsi
	WORD $0xe683; BYTE $0x0f // andl	$0xf, %esi
	WORD $0x014c; BYTE $0xd6 // addq	%r10, %rsi
	QUAD $0xfffe40b19410fac5; BYTE $0xff // vmovss	-0x1c0(%rcx,%rsi,4), %xmm2
	LONG $0x20eac148 // shrq	$0x20, %rdx
	WORD $0xe283; BYTE $0x0f // andl	$0xf, %edx
	WORD $0x014c; BYTE $0xd2 // addq	%r10, %rdx
	QUAD $0xfe8091942169e3c4; WORD $0xffff; BYTE $0x10 // vinsertps	$0x10, -0x180(%rcx,%rdx,4), %xmm2, %xmm2 # xmm2 = xmm2[0],mem[0],xmm2[2,3]
	LONG $0x2ce8c148 // shrq	$0x2c, %rax
	WORD $0xe083; BYTE $0x0f // andl	$0xf, %eax
	WORD $0x014c; BYTE $0xd0 // addq	%r10, %rax
	QUAD $0xfec081942169e3c4; WORD $0xffff; BYTE $0x20 // vinsertps	$0x20, -0x140(%rcx,%rax,4), %xmm2, %xmm2 # xmm2 = xmm2[0,1],mem[0],xmm2[3]
	LONG $0x24748b48; BYTE $0x38 // movq	0x38(%rsp), %rsi
	LONG $0x28efc148 // shrq	$0x28, %rdi
	WORD $0xe783; BYTE $0x0f // andl	$0xf, %edi
	WORD $0x014c; BYTE $0xd7 // addq	%r10, %rdi
	QUAD $0xff00b9942169e3c4; WORD $0xffff; BYTE $0x30 // vinsertps	$0x30, -0x100(%rcx,%rdi,4), %xmm2, %xmm2 # xmm2 = xmm2[0,1,2],mem[0]
	LONG $0x14e9c141 // shrl	$0x14, %r9d
	LONG $0x0fe18341 // andl	$0xf, %r9d
	WORD $0x014d; BYTE $0xd1 // addq	%r10, %r9
	QUAD $0xfd40899c107aa1c4; WORD $0xffff // vmovss	-0x2c0(%rcx,%r9,4), %xmm3
	LONG $0x247c8b48; BYTE $0x20 // movq	0x20(%rsp), %rdi
	LONG $0x10edc141 // shrl	$0x10, %r13d
	LONG $0x0fe58341 // andl	$0xf, %r13d
	WORD $0x014d; BYTE $0xd5 // addq	%r10, %r13
	QUAD $0xfd80a99c2161a3c4; WORD $0xffff; BYTE $0x10 // vinsertps	$0x10, -0x280(%rcx,%r13,4), %xmm3, %xmm3 # xmm3 = xmm3[0],mem[0],xmm3[2,3]
	LONG $0x1cebc141 // shrl	$0x1c, %r11d
	WORD $0x014d; BYTE $0xd3 // addq	%r10, %r11
	QUAD $0xfdc0999c2161a3c4; WORD $0xffff; BYTE $0x20 // vinsertps	$0x20, -0x240(%rcx,%r11,4), %xmm3, %xmm3 # xmm3 = xmm3[0,1],mem[0],xmm3[3]
	LONG $0x18e8c141 // shrl	$0x18, %r8d
	LONG $0x0fe08341 // andl	$0xf, %r8d
	WORD $0x014d; BYTE $0xd0 // addq	%r10, %r8
	QUAD $0xfe00819c2161a3c4; WORD $0xffff; BYTE $0x30 // vinsertps	$0x30, -0x200(%rcx,%r8,4), %xmm3, %xmm3 # xmm3 = xmm3[0,1,2],mem[0]
	LONG $0x24448b48; BYTE $0x28 // movq	0x28(%rsp), %rax
	WORD $0xe8c1; BYTE $0x04 // shrl	$0x4, %eax
	WORD $0xe083; BYTE $0x0f // andl	$0xf, %eax
	WORD $0x014c; BYTE $0xd0 // addq	%r10, %rax
	QUAD $0xfffc4081a410fac5; BYTE $0xff // vmovss	-0x3c0(%rcx,%rax,4), %xmm4
	LONG $0x24448b48; BYTE $0x30 // movq	0x30(%rsp), %rax
	WORD $0xe083; BYTE $0x0f // andl	$0xf, %eax
	WORD $0x014c; BYTE $0xd0 // addq	%r10, %rax
	QUAD $0xfc8081a42159e3c4; WORD $0xffff; BYTE $0x10 // vinsertps	$0x10, -0x380(%rcx,%rax,4), %xmm4, %xmm4 # xmm4 = xmm4[0],mem[0],xmm4[2,3]
	LONG $0x0cecc141 // shrl	$0xc, %r12d
	LONG $0x0fe48341 // andl	$0xf, %r12d
	WORD $0x014d; BYTE $0xd4 // addq	%r10, %r12
	QUAD $0xfcc0a1a42159a3c4; WORD $0xffff; BYTE $0x20 // vinsertps	$0x20, -0x340(%rcx,%r12,4), %xmm4, %xmm4 # xmm4 = xmm4[0,1],mem[0],xmm4[3]
	LONG $0x08efc141 // shrl	$0x8, %r15d
	LONG $0x0fe78341 // andl	$0xf, %r15d
	WORD $0x014d; BYTE $0xd7 // addq	%r10, %r15
	QUAD $0xfd00b9a42159a3c4; WORD $0xffff; BYTE $0x30 // vinsertps	$0x30, -0x300(%rcx,%r15,4), %xmm4, %xmm4 # xmm4 = xmm4[0,1,2],mem[0]
	LONG $0x186de3c4; WORD $0x01c9 // vinsertf128	$0x1, %xmm1, %ymm2, %ymm1
	LONG $0x185de3c4; WORD $0x01d3 // vinsertf128	$0x1, %xmm3, %ymm4, %ymm2
	LONG $0x48edf362; WORD $0xc91a; BYTE $0x01 // vinsertf64x4	$0x1, %ymm1, %zmm2, %zmm1
	LONG $0x487cf162; WORD $0x1410; BYTE $0x9f // vmovups	(%rdi,%rbx,4), %zmm2
	LONG $0x486cf162; WORD $0xc95c // vsubps	%zmm1, %zmm2, %zmm1
	LONG $0x4875f262; WORD $0xc1b8 // vfmadd231ps	%zmm1, %zmm1, %zmm0 # zmm0 = (zmm1 * zmm1) + zmm0
	LONG $0x10c38348 // addq	$0x10, %rbx
	LONG $0x00c28149; WORD $0x0001; BYTE $0x00 // addq	$0x100, %r10            # imm = 0x100
	LONG $0x08c68348 // addq	$0x8, %rsi
	LONG $0x245c3b48; BYTE $0x18 // cmpq	0x18(%rsp), %rbx
	LONG $0xfe378e0f; WORD $0xffff // jle	0x390 <int4L2DistancePrecomputedAvx512+0x50>
LBB1_4:
	LONG $0x48fdf362; WORD $0xc11b; BYTE $0x01 // vextractf64x4	$0x1, %zmm0, %ymm1
	LONG $0x487cf162; WORD $0xc158 // vaddps	%zmm1, %zmm0, %zmm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc8c6f9c5; BYTE $0x01 // vshufpd	$0x1, %xmm0, %xmm0, %xmm1 # xmm1 = xmm0[1,0]
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc816fac5 // vmovshdup	%xmm0, %xmm1    # xmm1 = xmm0[1,1,3,3]
	LONG $0xc958fac5 // vaddss	%xmm1, %xmm0, %xmm1
	LONG $0x244c8b4c; BYTE $0x08 // movq	0x8(%rsp), %r9
	WORD $0x394c; BYTE $0xcb // cmpq	%r9, %rbx
	WORD $0x767d // jge	0x601 <int4L2DistancePrecomputedAvx512+0x2c1>
	WORD $0x8948; BYTE $0xd8 // movq	%rbx, %rax
	WORD $0xd148; BYTE $0xe8 // shrq	%rax
	LONG $0x24048b4c // movq	(%rsp), %r8
	WORD $0x0149; BYTE $0xc0 // addq	%rax, %r8
	WORD $0x8948; BYTE $0xd8 // movq	%rbx, %rax
	LONG $0x04e0c148 // shlq	$0x4, %rax
	WORD $0x23eb // jmp	0x5c4 <int4L2DistancePrecomputedAvx512+0x284>
LBB1_9:
	LONG $0x02c38348 // addq	$0x2, %rbx
	WORD $0xff49; BYTE $0xc0 // incq	%r8
	LONG $0x20c08348 // addq	$0x20, %rax
	LONG $0xc828f8c5 // vmovaps	%xmm0, %xmm1
	WORD $0x394c; BYTE $0xcb // cmpq	%r9, %rbx
	WORD $0x417d // jge	0x605 <int4L2DistancePrecomputedAvx512+0x2c5>
LBB1_7:
	LONG $0x10b60f41 // movzbl	(%r8), %edx
	WORD $0xd689 // movl	%edx, %esi
	WORD $0xeec1; BYTE $0x04 // shrl	$0x4, %esi
	WORD $0x0148; BYTE $0xc6 // addq	%rax, %rsi
	LONG $0x0410fac5; BYTE $0x9f // vmovss	(%rdi,%rbx,4), %xmm0
	LONG $0x045cfac5; BYTE $0xb1 // vsubss	(%rcx,%rsi,4), %xmm0, %xmm0
	LONG $0xa979e2c4; BYTE $0xc1 // vfmadd213ss	%xmm1, %xmm0, %xmm0 # xmm0 = (xmm0 * xmm0) + xmm1
	LONG $0x01738d48 // leaq	0x1(%rbx), %rsi
	WORD $0x394c; BYTE $0xce // cmpq	%r9, %rsi
	WORD $0xc87d // jge	0x5b0 <int4L2DistancePrecomputedAvx512+0x270>
	WORD $0xe283; BYTE $0x0f // andl	$0xf, %edx
	WORD $0x0148; BYTE $0xc2 // addq	%rax, %rdx
	LONG $0x4c10fac5; WORD $0x049f // vmovss	0x4(%rdi,%rbx,4), %xmm1
	LONG $0x4c5cf2c5; WORD $0x4091 // vsubss	0x40(%rcx,%rdx,4), %xmm1, %xmm1
	LONG $0xb971e2c4; BYTE $0xc1 // vfmadd231ss	%xmm1, %xmm1, %xmm0 # xmm0 = (xmm1 * xmm1) + xmm0
	WORD $0xafeb // jmp	0x5b0 <int4L2DistancePrecomputedAvx512+0x270>
LBB1_5:
	LONG $0xc128f8c5 // vmovaps	%xmm1, %xmm0
LBB1_10:
	LONG $0x24448b48; BYTE $0x10 // movq	0x10(%rsp), %rax
	LONG $0x0011fac5 // vmovss	%xmm0, (%rax)
	LONG $0x40c48348 // addq	$0x40, %rsp
	BYTE $0x5b // popq	%rbx
	WORD $0x5c41 // popq	%r12
	WORD $0x5d41 // popq	%r13
	WORD $0x5e41 // popq	%r14
	WORD $0x5f41 // popq	%r15
	BYTE $0x5d // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

