// Code generated by internal/simd/cmd/generator. DO NOT EDIT.

//go:build !noasm && amd64

#include "textflag.h"

TEXT ·dotBatchAvx2(SB), NOSPLIT, $0-40
	MOVQ query+0(FP), DI
	MOVQ targets+8(FP), SI
	MOVQ dim+16(FP), DX
	MOVQ n+24(FP), CX
	MOVQ out+32(FP), R8

	BYTE $0x55 // pushq	%rbp
	WORD $0x5741 // pushq	%r15
	WORD $0x5641 // pushq	%r14
	WORD $0x5541 // pushq	%r13
	WORD $0x5441 // pushq	%r12
	BYTE $0x53 // pushq	%rbx
	LONG $0x28ec8348 // subq	$0x28, %rsp
	LONG $0x2404894c // movq	%r8, (%rsp)
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE LBB1_56
	LONG $0xf8428d48 // leaq	-0x8(%rdx), %rax
	LONG $0x20fa8348 // cmpq	$0x20, %rdx
	JGE LBB1_2
	LONG $0x08fa8348 // cmpq	$0x8, %rdx
	JGE LBB1_17
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xd2 // testq	%rdx, %rdx
	JLE LBB1_23
	LONG $0x0f10fac5 // vmovss	(%rdi), %xmm1
	WORD $0x8948; BYTE $0xc8 // movq	%rcx, %rax
	WORD $0xf748; BYTE $0xd8 // negq	%rax
	QUAD $0x00000000950c8d4c // leaq	(,%rdx,4), %r9
	LONG $0x0001ba41; WORD $0x0000 // movl	$0x1, %r10d
	JMP LBB1_26
LBB1_35:
	LONG $0x24048b4c // movq	(%rsp), %r8
	LONG $0x117a81c4; WORD $0x9054; BYTE $0xfc // vmovss	%xmm2, -0x4(%r8,%r10,4)
	LONG $0x10048d4e // leaq	(%rax,%r10), %r8
	WORD $0xff49; BYTE $0xc0 // incq	%r8
	WORD $0xff49; BYTE $0xc2 // incq	%r10
	WORD $0x014c; BYTE $0xce // addq	%r9, %rsi
	LONG $0x01f88349 // cmpq	$0x1, %r8
	JE LBB1_56
LBB1_26:
	WORD $0x3949; BYTE $0xca // cmpq	%rcx, %r10
	JGE LBB1_28
	LONG $0x0c180f42; BYTE $0x0e // prefetcht0	(%rsi,%r9)
LBB1_28:
	LONG $0x1610fac5 // vmovss	(%rsi), %xmm2
	LONG $0xa971e2c4; BYTE $0xd0 // vfmadd213ss	%xmm0, %xmm1, %xmm2 # xmm2 = (xmm1 * xmm2) + xmm0
	LONG $0x01fa8348 // cmpq	$0x1, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x04 // vmovss	0x4(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x0456 // vfmadd231ss	0x4(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	LONG $0x02fa8348 // cmpq	$0x2, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x08 // vmovss	0x8(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x0856 // vfmadd231ss	0x8(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	LONG $0x03fa8348 // cmpq	$0x3, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x0c // vmovss	0xc(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x0c56 // vfmadd231ss	0xc(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	LONG $0x04fa8348 // cmpq	$0x4, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x10 // vmovss	0x10(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x1056 // vfmadd231ss	0x10(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	LONG $0x05fa8348 // cmpq	$0x5, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x14 // vmovss	0x14(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x1456 // vfmadd231ss	0x14(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	LONG $0x06fa8348 // cmpq	$0x6, %rdx
	JE LBB1_35
	LONG $0x5f10fac5; BYTE $0x18 // vmovss	0x18(%rdi), %xmm3
	LONG $0xb961e2c4; WORD $0x1856 // vfmadd231ss	0x18(%rsi), %xmm3, %xmm2 # xmm2 = (xmm3 * mem) + xmm2
	JMP LBB1_35
LBB1_2:
	LONG $0xe04a8d4c // leaq	-0x20(%rdx), %r9
	QUAD $0x0000000095148d4c // leaq	(,%rdx,4), %r10
	LONG $0x809e8d4c; WORD $0x0000; BYTE $0x00 // leaq	0x80(%rsi), %r11
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	WORD $0x8948; BYTE $0xf3 // movq	%rsi, %rbx
	JMP LBB1_3
LBB1_15:
	LONG $0x24048b4c // movq	(%rsp), %r8
	LONG $0x117a81c4; WORD $0xb804 // vmovss	%xmm0, (%r8,%r15,4)
	WORD $0x014c; BYTE $0xd3 // addq	%r10, %rbx
	WORD $0x014d; BYTE $0xd3 // addq	%r10, %r11
	WORD $0x3949; BYTE $0xce // cmpq	%rcx, %r14
	JE LBB1_56
LBB1_3:
	WORD $0x894d; BYTE $0xf7 // movq	%r14, %r15
	WORD $0xff49; BYTE $0xc6 // incq	%r14
	WORD $0x3949; BYTE $0xce // cmpq	%rcx, %r14
	JGE LBB1_5
	WORD $0x894d; BYTE $0xf0 // movq	%r14, %r8
	LONG $0xc2af0f4c // imulq	%rdx, %r8
	LONG $0x0c180f42; BYTE $0x86 // prefetcht0	(%rsi,%r8,4)
LBB1_5:
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	WORD $0x894c; BYTE $0xdd // movq	%r11, %rbp
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0xd257e8c5 // vxorps	%xmm2, %xmm2, %xmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	WORD $0x3145; BYTE $0xe4 // xorl	%r12d, %r12d
LBB1_6:
	QUAD $0x000100a38c180f42; BYTE $0x00 // prefetcht0	0x100(%rbx,%r12,4)
	LONG $0x107ca1c4; WORD $0xa724 // vmovups	(%rdi,%r12,4), %ymm4
	LONG $0x107ca1c4; WORD $0xa76c; BYTE $0x20 // vmovups	0x20(%rdi,%r12,4), %ymm5
	LONG $0x107ca1c4; WORD $0xa774; BYTE $0x40 // vmovups	0x40(%rdi,%r12,4), %ymm6
	LONG $0x107ca1c4; WORD $0xa77c; BYTE $0x60 // vmovups	0x60(%rdi,%r12,4), %ymm7
	LONG $0xb85da2c4; WORD $0xa304 // vfmadd231ps	(%rbx,%r12,4), %ymm4, %ymm0 # ymm0 = (ymm4 * mem) + ymm0
	LONG $0xb855a2c4; WORD $0xa34c; BYTE $0x20 // vfmadd231ps	0x20(%rbx,%r12,4), %ymm5, %ymm1 # ymm1 = (ymm5 * mem) + ymm1
	LONG $0xb84da2c4; WORD $0xa354; BYTE $0x40 // vfmadd231ps	0x40(%rbx,%r12,4), %ymm6, %ymm2 # ymm2 = (ymm6 * mem) + ymm2
	LONG $0xb845a2c4; WORD $0xa35c; BYTE $0x60 // vfmadd231ps	0x60(%rbx,%r12,4), %ymm7, %ymm3 # ymm3 = (ymm7 * mem) + ymm3
	WORD $0x8949; BYTE $0xed // movq	%rbp, %r13
	LONG $0x20c48349 // addq	$0x20, %r12
	LONG $0x80c58148; WORD $0x0000; BYTE $0x00 // addq	$0x80, %rbp
	WORD $0x394d; BYTE $0xcc // cmpq	%r9, %r12
	JLE LBB1_6
	LONG $0xc058f4c5 // vaddps	%ymm0, %ymm1, %ymm0
	LONG $0xca58e4c5 // vaddps	%ymm2, %ymm3, %ymm1
	LONG $0xc058f4c5 // vaddps	%ymm0, %ymm1, %ymm0
	WORD $0x3949; BYTE $0xc4 // cmpq	%rax, %r12
	JGT LBB1_10
LBB1_8:
	LONG $0x107ca1c4; WORD $0xa70c // vmovups	(%rdi,%r12,4), %ymm1
	LONG $0xb875c2c4; WORD $0x0045 // vfmadd231ps	(%r13), %ymm1, %ymm0 # ymm0 = (ymm1 * mem) + ymm0
	LONG $0x08c48349 // addq	$0x8, %r12
	LONG $0x20c58349 // addq	$0x20, %r13
	WORD $0x3949; BYTE $0xc4 // cmpq	%rax, %r12
	JLE LBB1_8
LBB1_10:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x894d; BYTE $0xe5 // movq	%r12, %r13
	WORD $0x2949; BYTE $0xd5 // subq	%rdx, %r13
	JGE LBB1_15
	WORD $0xd589 // movl	%edx, %ebp
	WORD $0x2944; BYTE $0xe5 // subl	%r12d, %ebp
	WORD $0xe583; BYTE $0x03 // andl	$0x3, %ebp
	JE LBB1_13
LBB1_12:
	LONG $0x107aa1c4; WORD $0xa70c // vmovss	(%rdi,%r12,4), %xmm1
	LONG $0xb971a2c4; WORD $0xa304 // vfmadd231ss	(%rbx,%r12,4), %xmm1, %xmm0 # xmm0 = (xmm1 * mem) + xmm0
	WORD $0xff49; BYTE $0xc4 // incq	%r12
	WORD $0xff48; BYTE $0xcd // decq	%rbp
	JNE LBB1_12
LBB1_13:
	LONG $0xfcfd8349 // cmpq	$-0x4, %r13
	JHI LBB1_15
LBB1_14:
	LONG $0x107aa1c4; WORD $0xa70c // vmovss	(%rdi,%r12,4), %xmm1
	LONG $0x107aa1c4; WORD $0xa754; BYTE $0x04 // vmovss	0x4(%rdi,%r12,4), %xmm2
	LONG $0x9979a2c4; WORD $0xa30c // vfmadd132ss	(%rbx,%r12,4), %xmm0, %xmm1 # xmm1 = (xmm1 * mem) + xmm0
	LONG $0xb969a2c4; WORD $0xa34c; BYTE $0x04 // vfmadd231ss	0x4(%rbx,%r12,4), %xmm2, %xmm1 # xmm1 = (xmm2 * mem) + xmm1
	LONG $0x107aa1c4; WORD $0xa754; BYTE $0x08 // vmovss	0x8(%rdi,%r12,4), %xmm2
	LONG $0x9971a2c4; WORD $0xa354; BYTE $0x08 // vfmadd132ss	0x8(%rbx,%r12,4), %xmm1, %xmm2 # xmm2 = (xmm2 * mem) + xmm1
	LONG $0x107aa1c4; WORD $0xa744; BYTE $0x0c // vmovss	0xc(%rdi,%r12,4), %xmm0
	LONG $0x9969a2c4; WORD $0xa344; BYTE $0x0c // vfmadd132ss	0xc(%rbx,%r12,4), %xmm2, %xmm0 # xmm0 = (xmm0 * mem) + xmm2
	LONG $0x04c48349 // addq	$0x4, %r12
	WORD $0x394c; BYTE $0xe2 // cmpq	%r12, %rdx
	JNE LBB1_14
	JMP LBB1_15
LBB1_17:
	WORD $0x8949; BYTE $0xc0 // movq	%rax, %r8
	LONG $0xf8e08349 // andq	$-0x8, %r8
	WORD $0x8949; BYTE $0xc1 // movq	%rax, %r9
	LONG $0x03e9c149 // shrq	$0x3, %r9
	WORD $0xff49; BYTE $0xc1 // incq	%r9
	WORD $0x8949; BYTE $0xd2 // movq	%rdx, %r10
	WORD $0x294d; BYTE $0xc2 // subq	%r8, %r10
	LONG $0x08c08349 // addq	$0x8, %r8
	LONG $0xf7c28349 // addq	$-0x9, %r10
	LONG $0x2454894c; BYTE $0x10 // movq	%r10, 0x10(%rsp)
	WORD $0x8945; BYTE $0xcd // movl	%r9d, %r13d
	LONG $0x03e58341 // andl	$0x3, %r13d
	LONG $0xfce18349 // andq	$-0x4, %r9
	LONG $0x244c894c; BYTE $0x18 // movq	%r9, 0x18(%rsp)
	WORD $0x8941; BYTE $0xd1 // movl	%edx, %r9d
	LONG $0x03e18341 // andl	$0x3, %r9d
	LONG $0x244c894c; BYTE $0x08 // movq	%r9, 0x8(%rsp)
	LONG $0x607e8d4c // leaq	0x60(%rsi), %r15
	QUAD $0x0000000095248d4c // leaq	(,%rdx,4), %r12
	LONG $0x246c894c; BYTE $0x20 // movq	%r13, 0x20(%rsp)
	LONG $0x05e5c141 // shll	$0x5, %r13d
	WORD $0x3145; BYTE $0xdb // xorl	%r11d, %r11d
	WORD $0x8948; BYTE $0xf5 // movq	%rsi, %rbp
	JMP LBB1_18
LBB1_55:
	LONG $0x240c8b4c // movq	(%rsp), %r9
	LONG $0x117a81c4; WORD $0x9104 // vmovss	%xmm0, (%r9,%r10,4)
	WORD $0x014d; BYTE $0xe7 // addq	%r12, %r15
	WORD $0x014c; BYTE $0xe5 // addq	%r12, %rbp
	WORD $0x3949; BYTE $0xcb // cmpq	%rcx, %r11
	JE LBB1_56
LBB1_18:
	WORD $0x894d; BYTE $0xda // movq	%r11, %r10
	WORD $0xff49; BYTE $0xc3 // incq	%r11
	WORD $0x3949; BYTE $0xcb // cmpq	%rcx, %r11
	JGE LBB1_20
	WORD $0x894d; BYTE $0xd9 // movq	%r11, %r9
	LONG $0xcaaf0f4c // imulq	%rdx, %r9
	LONG $0x0c180f42; BYTE $0x8e // prefetcht0	(%rsi,%r9,4)
LBB1_20:
	LONG $0x18f88348 // cmpq	$0x18, %rax
	JAE LBB1_46
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP LBB1_48
LBB1_46:
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0x245c8b48; BYTE $0x18 // movq	0x18(%rsp), %rbx
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
LBB1_47:
	LONG $0x107ca1c4; WORD $0x8f04 // vmovups	(%rdi,%r9,4), %ymm0
	LONG $0x107ca1c4; WORD $0x8f54; BYTE $0x20 // vmovups	0x20(%rdi,%r9,4), %ymm2
	LONG $0x107ca1c4; WORD $0x8f5c; BYTE $0x40 // vmovups	0x40(%rdi,%r9,4), %ymm3
	LONG $0x107ca1c4; WORD $0x8f64; BYTE $0x60 // vmovups	0x60(%rdi,%r9,4), %ymm4
	LONG $0x987582c4; WORD $0x8f44; BYTE $0xa0 // vfmadd132ps	-0x60(%r15,%r9,4), %ymm1, %ymm0 # ymm0 = (ymm0 * mem) + ymm1
	LONG $0xb86d82c4; WORD $0x8f44; BYTE $0xc0 // vfmadd231ps	-0x40(%r15,%r9,4), %ymm2, %ymm0 # ymm0 = (ymm2 * mem) + ymm0
	LONG $0xb86582c4; WORD $0x8f44; BYTE $0xe0 // vfmadd231ps	-0x20(%r15,%r9,4), %ymm3, %ymm0 # ymm0 = (ymm3 * mem) + ymm0
	LONG $0xb85d82c4; WORD $0x8f04 // vfmadd231ps	(%r15,%r9,4), %ymm4, %ymm0 # ymm0 = (ymm4 * mem) + ymm0
	LONG $0x20c18349 // addq	$0x20, %r9
	LONG $0xc828fcc5 // vmovaps	%ymm0, %ymm1
	LONG $0xfcc38348 // addq	$-0x4, %rbx
	JNE LBB1_47
LBB1_48:
	LONG $0x247c8348; WORD $0x0020 // cmpq	$0x0, 0x20(%rsp)
	JE LBB1_51
	QUAD $0x000000008d1c8d4a // leaq	(,%r9,4), %rbx
	WORD $0x0148; BYTE $0xeb // addq	%rbp, %rbx
	LONG $0x8f0c8d4e // leaq	(%rdi,%r9,4), %r9
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
LBB1_50:
	LONG $0x107c81c4; WORD $0x310c // vmovups	(%r9,%r14), %ymm1
	LONG $0xb875a2c4; WORD $0x3304 // vfmadd231ps	(%rbx,%r14), %ymm1, %ymm0 # ymm0 = (ymm1 * mem) + ymm0
	LONG $0x20c68349 // addq	$0x20, %r14
	WORD $0x394d; BYTE $0xf5 // cmpq	%r14, %r13
	JNE LBB1_50
LBB1_51:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x3949; BYTE $0xd0 // cmpq	%rdx, %r8
	JGE LBB1_55
	LONG $0x245c8b48; BYTE $0x08 // movq	0x8(%rsp), %rbx
	WORD $0x894d; BYTE $0xc1 // movq	%r8, %r9
	WORD $0x8548; BYTE $0xdb // testq	%rbx, %rbx
	JE LBB1_54
LBB1_53:
	LONG $0x107aa1c4; WORD $0x8f0c // vmovss	(%rdi,%r9,4), %xmm1
	LONG $0xb971a2c4; WORD $0x8d44; BYTE $0x00 // vfmadd231ss	(%rbp,%r9,4), %xmm1, %xmm0 # xmm0 = (xmm1 * mem) + xmm0
	WORD $0xff49; BYTE $0xc1 // incq	%r9
	WORD $0xff48; BYTE $0xcb // decq	%rbx
	JNE LBB1_53
LBB1_54:
	LONG $0x247c8348; WORD $0x0310 // cmpq	$0x3, 0x10(%rsp)
	JLO LBB1_55
LBB1_57:
	LONG $0x107aa1c4; WORD $0x8f0c // vmovss	(%rdi,%r9,4), %xmm1
	LONG $0x107aa1c4; WORD $0x8f54; BYTE $0x04 // vmovss	0x4(%rdi,%r9,4), %xmm2
	LONG $0x9979a2c4; WORD $0x8d4c; BYTE $0x00 // vfmadd132ss	(%rbp,%r9,4), %xmm0, %xmm1 # xmm1 = (xmm1 * mem) + xmm0
	LONG $0xb969a2c4; WORD $0x8d4c; BYTE $0x04 // vfmadd231ss	0x4(%rbp,%r9,4), %xmm2, %xmm1 # xmm1 = (xmm2 * mem) + xmm1
	LONG $0x107aa1c4; WORD $0x8f54; BYTE $0x08 // vmovss	0x8(%rdi,%r9,4), %xmm2
	LONG $0x9971a2c4; WORD $0x8d54; BYTE $0x08 // vfmadd132ss	0x8(%rbp,%r9,4), %xmm1, %xmm2 # xmm2 = (xmm2 * mem) + xmm1
	LONG $0x107aa1c4; WORD $0x8f44; BYTE $0x0c // vmovss	0xc(%rdi,%r9,4), %xmm0
	LONG $0x9969a2c4; WORD $0x8d44; BYTE $0x0c // vfmadd132ss	0xc(%rbp,%r9,4), %xmm2, %xmm0 # xmm0 = (xmm0 * mem) + xmm2
	LONG $0x04c18349 // addq	$0x4, %r9
	WORD $0x394c; BYTE $0xca // cmpq	%r9, %rdx
	JNE LBB1_57
	JMP LBB1_55
LBB1_23:
	LONG $0x01f98348 // cmpq	$0x1, %rcx
	JNE LBB1_36
	WORD $0xff31 // xorl	%edi, %edi
LBB1_42:
	WORD $0xc1f6; BYTE $0x01 // testb	$0x1, %cl
	JE LBB1_56
	LONG $0x01478d48 // leaq	0x1(%rdi), %rax
	WORD $0x3948; BYTE $0xc8 // cmpq	%rcx, %rax
	JGE LBB1_45
	LONG $0xc2af0f48 // imulq	%rdx, %rax
	LONG $0x860c180f // prefetcht0	(%rsi,%rax,4)
LBB1_45:
	LONG $0x24048b48 // movq	(%rsp), %rax
	LONG $0x0411fac5; BYTE $0xb8 // vmovss	%xmm0, (%rax,%rdi,4)
LBB1_56:
	LONG $0x28c48348 // addq	$0x28, %rsp
	BYTE $0x5b // popq	%rbx
	WORD $0x5c41 // popq	%r12
	WORD $0x5d41 // popq	%r13
	WORD $0x5e41 // popq	%r14
	WORD $0x5f41 // popq	%r15
	BYTE $0x5d // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET
LBB1_36:
	QUAD $0xfffffffffffeb848; WORD $0x7fff // movabsq	$0x7ffffffffffffffe, %rax # imm = 0x7FFFFFFFFFFFFFFE
	WORD $0x2148; BYTE $0xc8 // andq	%rcx, %rax
	QUAD $0x00000000950c8d4c // leaq	(,%rdx,4), %r9
	QUAD $0x00000000d5148d4c // leaq	(,%rdx,8), %r10
	WORD $0xdb31 // xorl	%ebx, %ebx
	WORD $0x8949; BYTE $0xf3 // movq	%rsi, %r11
	LONG $0x24048b4c // movq	(%rsp), %r8
	JMP LBB1_37
LBB1_41:
	LONG $0x117ac1c4; WORD $0x9844; BYTE $0x04 // vmovss	%xmm0, 0x4(%r8,%rbx,4)
	WORD $0x014d; BYTE $0xd3 // addq	%r10, %r11
	WORD $0x8948; BYTE $0xfb // movq	%rdi, %rbx
	WORD $0x3948; BYTE $0xf8 // cmpq	%rdi, %rax
	JE LBB1_42
LBB1_37:
	LONG $0x017b8d48 // leaq	0x1(%rbx), %rdi
	WORD $0x3948; BYTE $0xcf // cmpq	%rcx, %rdi
	JGE LBB1_39
	LONG $0x0c180f43; BYTE $0x0b // prefetcht0	(%r11,%r9)
LBB1_39:
	LONG $0x243c8b48 // movq	(%rsp), %rdi
	LONG $0x0411fac5; BYTE $0x9f // vmovss	%xmm0, (%rdi,%rbx,4)
	LONG $0x027b8d48 // leaq	0x2(%rbx), %rdi
	WORD $0x3948; BYTE $0xcf // cmpq	%rcx, %rdi
	JGE LBB1_41
	LONG $0x0c180f43; BYTE $0x13 // prefetcht0	(%r11,%r10)
	JMP LBB1_41

TEXT ·squaredL2BatchAvx2(SB), NOSPLIT, $0-40
	MOVQ query+0(FP), DI
	MOVQ targets+8(FP), SI
	MOVQ dim+16(FP), DX
	MOVQ n+24(FP), CX
	MOVQ out+32(FP), R8

	BYTE $0x55 // pushq	%rbp
	WORD $0x5741 // pushq	%r15
	WORD $0x5641 // pushq	%r14
	WORD $0x5541 // pushq	%r13
	WORD $0x5441 // pushq	%r12
	BYTE $0x53 // pushq	%rbx
	LONG $0x28ec8348 // subq	$0x28, %rsp
	LONG $0x2404894c // movq	%r8, (%rsp)
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE LBB0_56
	LONG $0xf8428d48 // leaq	-0x8(%rdx), %rax
	LONG $0x20fa8348 // cmpq	$0x20, %rdx
	JGE LBB0_2
	LONG $0x08fa8348 // cmpq	$0x8, %rdx
	JGE LBB0_17
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xd2 // testq	%rdx, %rdx
	JLE LBB0_23
	LONG $0x0f10fac5 // vmovss	(%rdi), %xmm1
	WORD $0x8948; BYTE $0xc8 // movq	%rcx, %rax
	WORD $0xf748; BYTE $0xd8 // negq	%rax
	QUAD $0x00000000950c8d4c // leaq	(,%rdx,4), %r9
	LONG $0x0001ba41; WORD $0x0000 // movl	$0x1, %r10d
	JMP LBB0_26
LBB0_35:
	LONG $0x24048b4c // movq	(%rsp), %r8
	LONG $0x117a81c4; WORD $0x9054; BYTE $0xfc // vmovss	%xmm2, -0x4(%r8,%r10,4)
	LONG $0x10048d4e // leaq	(%rax,%r10), %r8
	WORD $0xff49; BYTE $0xc0 // incq	%r8
	WORD $0xff49; BYTE $0xc2 // incq	%r10
	WORD $0x014c; BYTE $0xce // addq	%r9, %rsi
	LONG $0x01f88349 // cmpq	$0x1, %r8
	JE LBB0_56
LBB0_26:
	WORD $0x3949; BYTE $0xca // cmpq	%rcx, %r10
	JGE LBB0_28
	LONG $0x0c180f42; BYTE $0x0e // prefetcht0	(%rsi,%r9)
LBB0_28:
	LONG $0x165cf2c5 // vsubss	(%rsi), %xmm1, %xmm2
	LONG $0xa969e2c4; BYTE $0xd0 // vfmadd213ss	%xmm0, %xmm2, %xmm2 # xmm2 = (xmm2 * xmm2) + xmm0
	LONG $0x01fa8348 // cmpq	$0x1, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x04 // vmovss	0x4(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x04 // vsubss	0x4(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	LONG $0x02fa8348 // cmpq	$0x2, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x08 // vmovss	0x8(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x08 // vsubss	0x8(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	LONG $0x03fa8348 // cmpq	$0x3, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x0c // vmovss	0xc(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x0c // vsubss	0xc(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	LONG $0x04fa8348 // cmpq	$0x4, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x10 // vmovss	0x10(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x10 // vsubss	0x10(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	LONG $0x05fa8348 // cmpq	$0x5, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x14 // vmovss	0x14(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x14 // vsubss	0x14(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	LONG $0x06fa8348 // cmpq	$0x6, %rdx
	JE LBB0_35
	LONG $0x5f10fac5; BYTE $0x18 // vmovss	0x18(%rdi), %xmm3
	LONG $0x5e5ce2c5; BYTE $0x18 // vsubss	0x18(%rsi), %xmm3, %xmm3
	LONG $0xb961e2c4; BYTE $0xd3 // vfmadd231ss	%xmm3, %xmm3, %xmm2 # xmm2 = (xmm3 * xmm3) + xmm2
	JMP LBB0_35
LBB0_2:
	LONG $0xe04a8d4c // leaq	-0x20(%rdx), %r9
	QUAD $0x0000000095148d4c // leaq	(,%rdx,4), %r10
	LONG $0x809e8d4c; WORD $0x0000; BYTE $0x00 // leaq	0x80(%rsi), %r11
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	WORD $0x8948; BYTE $0xf3 // movq	%rsi, %rbx
	JMP LBB0_3
LBB0_15:
	LONG $0x24048b4c // movq	(%rsp), %r8
	LONG $0x117a81c4; WORD $0xb804 // vmovss	%xmm0, (%r8,%r15,4)
	WORD $0x014c; BYTE $0xd3 // addq	%r10, %rbx
	WORD $0x014d; BYTE $0xd3 // addq	%r10, %r11
	WORD $0x3949; BYTE $0xce // cmpq	%rcx, %r14
	JE LBB0_56
LBB0_3:
	WORD $0x894d; BYTE $0xf7 // movq	%r14, %r15
	WORD $0xff49; BYTE $0xc6 // incq	%r14
	WORD $0x3949; BYTE $0xce // cmpq	%rcx, %r14
	JGE LBB0_5
	WORD $0x894d; BYTE $0xf0 // movq	%r14, %r8
	LONG $0xc2af0f4c // imulq	%rdx, %r8
	LONG $0x0c180f42; BYTE $0x86 // prefetcht0	(%rsi,%r8,4)
LBB0_5:
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	WORD $0x894c; BYTE $0xdd // movq	%r11, %rbp
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0xd257e8c5 // vxorps	%xmm2, %xmm2, %xmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	WORD $0x3145; BYTE $0xe4 // xorl	%r12d, %r12d
LBB0_6:
	QUAD $0x000100a38c180f42; BYTE $0x00 // prefetcht0	0x100(%rbx,%r12,4)
	LONG $0x107ca1c4; WORD $0xa724 // vmovups	(%rdi,%r12,4), %ymm4
	LONG $0x107ca1c4; WORD $0xa76c; BYTE $0x20 // vmovups	0x20(%rdi,%r12,4), %ymm5
	LONG $0x107ca1c4; WORD $0xa774; BYTE $0x40 // vmovups	0x40(%rdi,%r12,4), %ymm6
	LONG $0x107ca1c4; WORD $0xa77c; BYTE $0x60 // vmovups	0x60(%rdi,%r12,4), %ymm7
	LONG $0x5c5ca1c4; WORD $0xa324 // vsubps	(%rbx,%r12,4), %ymm4, %ymm4
	LONG $0x5c54a1c4; WORD $0xa36c; BYTE $0x20 // vsubps	0x20(%rbx,%r12,4), %ymm5, %ymm5
	LONG $0x5c4ca1c4; WORD $0xa374; BYTE $0x40 // vsubps	0x40(%rbx,%r12,4), %ymm6, %ymm6
	LONG $0x5c44a1c4; WORD $0xa37c; BYTE $0x60 // vsubps	0x60(%rbx,%r12,4), %ymm7, %ymm7
	WORD $0x8949; BYTE $0xed // movq	%rbp, %r13
	LONG $0xb85de2c4; BYTE $0xc4 // vfmadd231ps	%ymm4, %ymm4, %ymm0 # ymm0 = (ymm4 * ymm4) + ymm0
	LONG $0xb855e2c4; BYTE $0xcd // vfmadd231ps	%ymm5, %ymm5, %ymm1 # ymm1 = (ymm5 * ymm5) + ymm1
	LONG $0xb84de2c4; BYTE $0xd6 // vfmadd231ps	%ymm6, %ymm6, %ymm2 # ymm2 = (ymm6 * ymm6) + ymm2
	LONG $0xb845e2c4; BYTE $0xdf // vfmadd231ps	%ymm7, %ymm7, %ymm3 # ymm3 = (ymm7 * ymm7) + ymm3
	LONG $0x20c48349 // addq	$0x20, %r12
	LONG $0x80c58148; WORD $0x0000; BYTE $0x00 // addq	$0x80, %rbp
	WORD $0x394d; BYTE $0xcc // cmpq	%r9, %r12
	JLE LBB0_6
	LONG $0xc058f4c5 // vaddps	%ymm0, %ymm1, %ymm0
	LONG $0xca58e4c5 // vaddps	%ymm2, %ymm3, %ymm1
	LONG $0xc058f4c5 // vaddps	%ymm0, %ymm1, %ymm0
	WORD $0x3949; BYTE $0xc4 // cmpq	%rax, %r12
	JGT LBB0_10
LBB0_8:
	LONG $0x107ca1c4; WORD $0xa70c // vmovups	(%rdi,%r12,4), %ymm1
	LONG $0x5c74c1c4; WORD $0x004d // vsubps	(%r13), %ymm1, %ymm1
	LONG $0xb875e2c4; BYTE $0xc1 // vfmadd231ps	%ymm1, %ymm1, %ymm0 # ymm0 = (ymm1 * ymm1) + ymm0
	LONG $0x08c48349 // addq	$0x8, %r12
	LONG $0x20c58349 // addq	$0x20, %r13
	WORD $0x3949; BYTE $0xc4 // cmpq	%rax, %r12
	JLE LBB0_8
LBB0_10:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x894d; BYTE $0xe5 // movq	%r12, %r13
	WORD $0x2949; BYTE $0xd5 // subq	%rdx, %r13
	JGE LBB0_15
	WORD $0xd589 // movl	%edx, %ebp
	WORD $0x2944; BYTE $0xe5 // subl	%r12d, %ebp
	WORD $0xe583; BYTE $0x03 // andl	$0x3, %ebp
	JE LBB0_13
LBB0_12:
	LONG $0x107aa1c4; WORD $0xa70c // vmovss	(%rdi,%r12,4), %xmm1
	LONG $0x5c72a1c4; WORD $0xa30c // vsubss	(%rbx,%r12,4), %xmm1, %xmm1
	LONG $0xb971e2c4; BYTE $0xc1 // vfmadd231ss	%xmm1, %xmm1, %xmm0 # xmm0 = (xmm1 * xmm1) + xmm0
	WORD $0xff49; BYTE $0xc4 // incq	%r12
	WORD $0xff48; BYTE $0xcd // decq	%rbp
	JNE LBB0_12
LBB0_13:
	LONG $0xfcfd8349 // cmpq	$-0x4, %r13
	JHI LBB0_15
LBB0_14:
	LONG $0x107aa1c4; WORD $0xa70c // vmovss	(%rdi,%r12,4), %xmm1
	LONG $0x107aa1c4; WORD $0xa754; BYTE $0x04 // vmovss	0x4(%rdi,%r12,4), %xmm2
	LONG $0x5c72a1c4; WORD $0xa30c // vsubss	(%rbx,%r12,4), %xmm1, %xmm1
	LONG $0x5c6aa1c4; WORD $0xa354; BYTE $0x04 // vsubss	0x4(%rbx,%r12,4), %xmm2, %xmm2
	LONG $0xa971e2c4; BYTE $0xc8 // vfmadd213ss	%xmm0, %xmm1, %xmm1 # xmm1 = (xmm1 * xmm1) + xmm0
	LONG $0x107aa1c4; WORD $0xa744; BYTE $0x08 // vmovss	0x8(%rdi,%r12,4), %xmm0
	LONG $0x5c7aa1c4; WORD $0xa35c; BYTE $0x08 // vsubss	0x8(%rbx,%r12,4), %xmm0, %xmm3
	LONG $0xa969e2c4; BYTE $0xd1 // vfmadd213ss	%xmm1, %xmm2, %xmm2 # xmm2 = (xmm2 * xmm2) + xmm1
	LONG $0x107aa1c4; WORD $0xa744; BYTE $0x0c // vmovss	0xc(%rdi,%r12,4), %xmm0
	LONG $0x5c7aa1c4; WORD $0xa344; BYTE $0x0c // vsubss	0xc(%rbx,%r12,4), %xmm0, %xmm0
	LONG $0xa961e2c4; BYTE $0xda // vfmadd213ss	%xmm2, %xmm3, %xmm3 # xmm3 = (xmm3 * xmm3) + xmm2
	LONG $0xa979e2c4; BYTE $0xc3 // vfmadd213ss	%xmm3, %xmm0, %xmm0 # xmm0 = (xmm0 * xmm0) + xmm3
	LONG $0x04c48349 // addq	$0x4, %r12
	WORD $0x394c; BYTE $0xe2 // cmpq	%r12, %rdx
	JNE LBB0_14
	JMP LBB0_15
LBB0_17:
	WORD $0x8949; BYTE $0xc0 // movq	%rax, %r8
	LONG $0xf8e08349 // andq	$-0x8, %r8
	WORD $0x8949; BYTE $0xc1 // movq	%rax, %r9
	LONG $0x03e9c149 // shrq	$0x3, %r9
	WORD $0xff49; BYTE $0xc1 // incq	%r9
	WORD $0x8949; BYTE $0xd2 // movq	%rdx, %r10
	WORD $0x294d; BYTE $0xc2 // subq	%r8, %r10
	LONG $0x08c08349 // addq	$0x8, %r8
	LONG $0xf7c28349 // addq	$-0x9, %r10
	LONG $0x2454894c; BYTE $0x10 // movq	%r10, 0x10(%rsp)
	WORD $0x8945; BYTE $0xcd // movl	%r9d, %r13d
	LONG $0x03e58341 // andl	$0x3, %r13d
	LONG $0xfce18349 // andq	$-0x4, %r9
	LONG $0x244c894c; BYTE $0x18 // movq	%r9, 0x18(%rsp)
	WORD $0x8941; BYTE $0xd1 // movl	%edx, %r9d
	LONG $0x03e18341 // andl	$0x3, %r9d
	LONG $0x244c894c; BYTE $0x08 // movq	%r9, 0x8(%rsp)
	LONG $0x607e8d4c // leaq	0x60(%rsi), %r15
	QUAD $0x0000000095248d4c // leaq	(,%rdx,4), %r12
	LONG $0x246c894c; BYTE $0x20 // movq	%r13, 0x20(%rsp)
	LONG $0x05e5c141 // shll	$0x5, %r13d
	WORD $0x3145; BYTE $0xdb // xorl	%r11d, %r11d
	WORD $0x8948; BYTE $0xf5 // movq	%rsi, %rbp
	JMP LBB0_18
LBB0_55:
	LONG $0x240c8b4c // movq	(%rsp), %r9
	LONG $0x117a81c4; WORD $0x9104 // vmovss	%xmm0, (%r9,%r10,4)
	WORD $0x014d; BYTE $0xe7 // addq	%r12, %r15
	WORD $0x014c; BYTE $0xe5 // addq	%r12, %rbp
	WORD $0x3949; BYTE $0xcb // cmpq	%rcx, %r11
	JE LBB0_56
LBB0_18:
	WORD $0x894d; BYTE $0xda // movq	%r11, %r10
	WORD $0xff49; BYTE $0xc3 // incq	%r11
	WORD $0x3949; BYTE $0xcb // cmpq	%rcx, %r11
	JGE LBB0_20
	WORD $0x894d; BYTE $0xd9 // movq	%r11, %r9
	LONG $0xcaaf0f4c // imulq	%rdx, %r9
	LONG $0x0c180f42; BYTE $0x8e // prefetcht0	(%rsi,%r9,4)
LBB0_20:
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x18f88348 // cmpq	$0x18, %rax
	JAE LBB0_46
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP LBB0_48
LBB0_46:
	LONG $0x245c8b48; BYTE $0x18 // movq	0x18(%rsp), %rbx
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
LBB0_47:
	LONG $0x107ca1c4; WORD $0x8f0c // vmovups	(%rdi,%r9,4), %ymm1
	LONG $0x107ca1c4; WORD $0x8f54; BYTE $0x20 // vmovups	0x20(%rdi,%r9,4), %ymm2
	LONG $0x107ca1c4; WORD $0x8f5c; BYTE $0x40 // vmovups	0x40(%rdi,%r9,4), %ymm3
	LONG $0x107ca1c4; WORD $0x8f64; BYTE $0x60 // vmovups	0x60(%rdi,%r9,4), %ymm4
	LONG $0x5c7481c4; WORD $0x8f4c; BYTE $0xa0 // vsubps	-0x60(%r15,%r9,4), %ymm1, %ymm1
	LONG $0xa875e2c4; BYTE $0xc8 // vfmadd213ps	%ymm0, %ymm1, %ymm1 # ymm1 = (ymm1 * ymm1) + ymm0
	LONG $0x5c6c81c4; WORD $0x8f54; BYTE $0xc0 // vsubps	-0x40(%r15,%r9,4), %ymm2, %ymm2
	LONG $0xa86de2c4; BYTE $0xd1 // vfmadd213ps	%ymm1, %ymm2, %ymm2 # ymm2 = (ymm2 * ymm2) + ymm1
	LONG $0x5c6481c4; WORD $0x8f4c; BYTE $0xe0 // vsubps	-0x20(%r15,%r9,4), %ymm3, %ymm1
	LONG $0x5c5c81c4; WORD $0x8f04 // vsubps	(%r15,%r9,4), %ymm4, %ymm0
	LONG $0xa875e2c4; BYTE $0xca // vfmadd213ps	%ymm2, %ymm1, %ymm1 # ymm1 = (ymm1 * ymm1) + ymm2
	LONG $0xa87de2c4; BYTE $0xc1 // vfmadd213ps	%ymm1, %ymm0, %ymm0 # ymm0 = (ymm0 * ymm0) + ymm1
	LONG $0x20c18349 // addq	$0x20, %r9
	LONG $0xfcc38348 // addq	$-0x4, %rbx
	JNE LBB0_47
LBB0_48:
	LONG $0x247c8348; WORD $0x0020 // cmpq	$0x0, 0x20(%rsp)
	JE LBB0_51
	QUAD $0x000000008d1c8d4a // leaq	(,%r9,4), %rbx
	WORD $0x0148; BYTE $0xeb // addq	%rbp, %rbx
	LONG $0x8f0c8d4e // leaq	(%rdi,%r9,4), %r9
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
LBB0_50:
	LONG $0x107c81c4; WORD $0x310c // vmovups	(%r9,%r14), %ymm1
	LONG $0x5c74a1c4; WORD $0x330c // vsubps	(%rbx,%r14), %ymm1, %ymm1
	LONG $0xb875e2c4; BYTE $0xc1 // vfmadd231ps	%ymm1, %ymm1, %ymm0 # ymm0 = (ymm1 * ymm1) + ymm0
	LONG $0x20c68349 // addq	$0x20, %r14
	WORD $0x394d; BYTE $0xf5 // cmpq	%r14, %r13
	JNE LBB0_50
LBB0_51:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5 // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x3949; BYTE $0xd0 // cmpq	%rdx, %r8
	JGE LBB0_55
	LONG $0x245c8b48; BYTE $0x08 // movq	0x8(%rsp), %rbx
	WORD $0x894d; BYTE $0xc1 // movq	%r8, %r9
	WORD $0x8548; BYTE $0xdb // testq	%rbx, %rbx
	JE LBB0_54
LBB0_53:
	LONG $0x107aa1c4; WORD $0x8f0c // vmovss	(%rdi,%r9,4), %xmm1
	LONG $0x5c72a1c4; WORD $0x8d4c; BYTE $0x00 // vsubss	(%rbp,%r9,4), %xmm1, %xmm1
	LONG $0xb971e2c4; BYTE $0xc1 // vfmadd231ss	%xmm1, %xmm1, %xmm0 # xmm0 = (xmm1 * xmm1) + xmm0
	WORD $0xff49; BYTE $0xc1 // incq	%r9
	WORD $0xff48; BYTE $0xcb // decq	%rbx
	JNE LBB0_53
LBB0_54:
	LONG $0x247c8348; WORD $0x0310 // cmpq	$0x3, 0x10(%rsp)
	JLO LBB0_55
LBB0_57:
	LONG $0x107aa1c4; WORD $0x8f0c // vmovss	(%rdi,%r9,4), %xmm1
	LONG $0x107aa1c4; WORD $0x8f54; BYTE $0x04 // vmovss	0x4(%rdi,%r9,4), %xmm2
	LONG $0x5c72a1c4; WORD $0x8d4c; BYTE $0x00 // vsubss	(%rbp,%r9,4), %xmm1, %xmm1
	LONG $0x5c6aa1c4; WORD $0x8d54; BYTE $0x04 // vsubss	0x4(%rbp,%r9,4), %xmm2, %xmm2
	LONG $0xa971e2c4; BYTE $0xc8 // vfmadd213ss	%xmm0, %xmm1, %xmm1 # xmm1 = (xmm1 * xmm1) + xmm0
	LONG $0x107aa1c4; WORD $0x8f44; BYTE $0x08 // vmovss	0x8(%rdi,%r9,4), %xmm0
	LONG $0x5c7aa1c4; WORD $0x8d5c; BYTE $0x08 // vsubss	0x8(%rbp,%r9,4), %xmm0, %xmm3
	LONG $0xa969e2c4; BYTE $0xd1 // vfmadd213ss	%xmm1, %xmm2, %xmm2 # xmm2 = (xmm2 * xmm2) + xmm1
	LONG $0x107aa1c4; WORD $0x8f44; BYTE $0x0c // vmovss	0xc(%rdi,%r9,4), %xmm0
	LONG $0x5c7aa1c4; WORD $0x8d44; BYTE $0x0c // vsubss	0xc(%rbp,%r9,4), %xmm0, %xmm0
	LONG $0xa961e2c4; BYTE $0xda // vfmadd213ss	%xmm2, %xmm3, %xmm3 # xmm3 = (xmm3 * xmm3) + xmm2
	LONG $0xa979e2c4; BYTE $0xc3 // vfmadd213ss	%xmm3, %xmm0, %xmm0 # xmm0 = (xmm0 * xmm0) + xmm3
	LONG $0x04c18349 // addq	$0x4, %r9
	WORD $0x394c; BYTE $0xca // cmpq	%r9, %rdx
	JNE LBB0_57
	JMP LBB0_55
LBB0_23:
	LONG $0x01f98348 // cmpq	$0x1, %rcx
	JNE LBB0_36
	WORD $0xff31 // xorl	%edi, %edi
LBB0_42:
	WORD $0xc1f6; BYTE $0x01 // testb	$0x1, %cl
	JE LBB0_56
	LONG $0x01478d48 // leaq	0x1(%rdi), %rax
	WORD $0x3948; BYTE $0xc8 // cmpq	%rcx, %rax
	JGE LBB0_45
	LONG $0xc2af0f48 // imulq	%rdx, %rax
	LONG $0x860c180f // prefetcht0	(%rsi,%rax,4)
LBB0_45:
	LONG $0x24048b48 // movq	(%rsp), %rax
	LONG $0x0411fac5; BYTE $0xb8 // vmovss	%xmm0, (%rax,%rdi,4)
LBB0_56:
	LONG $0x28c48348 // addq	$0x28, %rsp
	BYTE $0x5b // popq	%rbx
	WORD $0x5c41 // popq	%r12
	WORD $0x5d41 // popq	%r13
	WORD $0x5e41 // popq	%r14
	WORD $0x5f41 // popq	%r15
	BYTE $0x5d // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET
LBB0_36:
	QUAD $0xfffffffffffeb848; WORD $0x7fff // movabsq	$0x7ffffffffffffffe, %rax # imm = 0x7FFFFFFFFFFFFFFE
	WORD $0x2148; BYTE $0xc8 // andq	%rcx, %rax
	QUAD $0x00000000950c8d4c // leaq	(,%rdx,4), %r9
	QUAD $0x00000000d5148d4c // leaq	(,%rdx,8), %r10
	WORD $0xdb31 // xorl	%ebx, %ebx
	WORD $0x8949; BYTE $0xf3 // movq	%rsi, %r11
	LONG $0x24048b4c // movq	(%rsp), %r8
	JMP LBB0_37
LBB0_41:
	LONG $0x117ac1c4; WORD $0x9844; BYTE $0x04 // vmovss	%xmm0, 0x4(%r8,%rbx,4)
	WORD $0x014d; BYTE $0xd3 // addq	%r10, %r11
	WORD $0x8948; BYTE $0xfb // movq	%rdi, %rbx
	WORD $0x3948; BYTE $0xf8 // cmpq	%rdi, %rax
	JE LBB0_42
LBB0_37:
	LONG $0x017b8d48 // leaq	0x1(%rbx), %rdi
	WORD $0x3948; BYTE $0xcf // cmpq	%rcx, %rdi
	JGE LBB0_39
	LONG $0x0c180f43; BYTE $0x0b // prefetcht0	(%r11,%r9)
LBB0_39:
	LONG $0x243c8b48 // movq	(%rsp), %rdi
	LONG $0x0411fac5; BYTE $0x9f // vmovss	%xmm0, (%rdi,%rbx,4)
	LONG $0x027b8d48 // leaq	0x2(%rbx), %rdi
	WORD $0x3948; BYTE $0xcf // cmpq	%rcx, %rdi
	JGE LBB0_41
	LONG $0x0c180f43; BYTE $0x13 // prefetcht0	(%r11,%r10)
	JMP LBB0_41

