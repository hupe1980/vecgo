// Code generated by internal/simd/cmd/generator. DO NOT EDIT.

//go:build !noasm && amd64

#include "textflag.h"

TEXT 路dotProductAvx512(SB), NOSPLIT, $0-32
	MOVQ vec1+0(FP), DI
	MOVQ vec2+8(FP), SI
	MOVQ n+16(FP), DX
	MOVQ result+24(FP), CX

	LONG $0x3f428d4c // leaq	0x3f(%rdx), %r8
	WORD $0x8548; BYTE $0xd2 // testq	%rdx, %rdx
	LONG $0xc2490f4c // cmovnsq	%rdx, %r8
	WORD $0x894d; BYTE $0xc1 // movq	%r8, %r9
	LONG $0xc0e18349 // andq	$-0x40, %r9
	WORD $0x8948; BYTE $0xd0 // movq	%rdx, %rax
	WORD $0x294c; BYTE $0xc8 // subq	%r9, %rax
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x40fa8348 // cmpq	$0x40, %rdx
	JLT LBB0_4
	LONG $0x06f8c149 // sarq	$0x6, %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0xd257e8c5 // vxorps	%xmm2, %xmm2, %xmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
LBB0_2:
	QUAD $0x0002000f8c180f42; BYTE $0x00 // prefetcht0	0x200(%rdi,%r9)
	QUAD $0x0002000e8c180f42; BYTE $0x00 // prefetcht0	0x200(%rsi,%r9)
	LONG $0x487cb162; WORD $0x2410; BYTE $0x0f // vmovups	(%rdi,%r9), %zmm4
	QUAD $0x010f6c10487cb162 // vmovups	0x40(%rdi,%r9), %zmm5
	QUAD $0x020f7410487cb162 // vmovups	0x80(%rdi,%r9), %zmm6
	QUAD $0x030f7c10487cb162 // vmovups	0xc0(%rdi,%r9), %zmm7
	LONG $0x485db262; WORD $0x04b8; BYTE $0x0e // vfmadd231ps	(%rsi,%r9), %zmm4, %zmm0 # zmm0 = (zmm4 * mem) + zmm0
	QUAD $0x010e4cb84855b262 // vfmadd231ps	0x40(%rsi,%r9), %zmm5, %zmm1 # zmm1 = (zmm5 * mem) + zmm1
	QUAD $0x020e54b8484db262 // vfmadd231ps	0x80(%rsi,%r9), %zmm6, %zmm2 # zmm2 = (zmm6 * mem) + zmm2
	QUAD $0x030e5cb84845b262 // vfmadd231ps	0xc0(%rsi,%r9), %zmm7, %zmm3 # zmm3 = (zmm7 * mem) + zmm3
	LONG $0x00c18149; WORD $0x0001; BYTE $0x00 // addq	$0x100, %r9             # imm = 0x100
	WORD $0xff49; BYTE $0xc8 // decq	%r8
	JNE LBB0_2
	LONG $0x4874f162; WORD $0xc058 // vaddps	%zmm0, %zmm1, %zmm0
	LONG $0x4864f162; WORD $0xca58 // vaddps	%zmm2, %zmm3, %zmm1
	LONG $0x4874f162; WORD $0xc058 // vaddps	%zmm0, %zmm1, %zmm0
LBB0_4:
	LONG $0x48fdf362; WORD $0xc11b; BYTE $0x01 // vextractf64x4	$0x1, %zmm0, %ymm1
	LONG $0x487cf162; WORD $0xc158 // vaddps	%zmm1, %zmm0, %zmm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc8c6f9c5; BYTE $0x01 // vshufpd	$0x1, %xmm0, %xmm0, %xmm1 # xmm1 = xmm0[1,0]
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc816fac5 // vmovshdup	%xmm0, %xmm1    # xmm1 = xmm0[1,1,3,3]
	LONG $0xc158fac5 // vaddss	%xmm1, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE LBB0_7
	WORD $0x8949; BYTE $0xd0 // movq	%rdx, %r8
	WORD $0x2949; BYTE $0xc0 // subq	%rax, %r8
LBB0_6:
	LONG $0x107aa1c4; WORD $0x870c // vmovss	(%rdi,%r8,4), %xmm1
	LONG $0xb971a2c4; WORD $0x8604 // vfmadd231ss	(%rsi,%r8,4), %xmm1, %xmm0 # xmm0 = (xmm1 * mem) + xmm0
	WORD $0xff49; BYTE $0xc0 // incq	%r8
	WORD $0x3949; BYTE $0xd0 // cmpq	%rdx, %r8
	JLT LBB0_6
LBB0_7:
	LONG $0x0111fac5 // vmovss	%xmm0, (%rcx)
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路pqAdcLookupAvx512(SB), NOSPLIT, $0-40
	MOVQ table+0(FP), DI
	MOVQ codes+8(FP), SI
	MOVQ m+16(FP), DX
	MOVQ result+24(FP), CX
	MOVQ offsets_ptr+32(FP), R8

	BYTE $0x53 // pushq	%rbx
	LONG $0x10fa8348 // cmpq	$0x10, %rdx
	JGE LBB2_2
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	WORD $0xc031 // xorl	%eax, %eax
	JMP LBB2_10
LBB2_2:
	LONG $0x48fed162; WORD $0x006f // vmovdqu64	(%r8), %zmm0
	LONG $0xf04a8d4c // leaq	-0x10(%rdx), %r9
	WORD $0x894c; BYTE $0xc8 // movq	%r9, %rax
	LONG $0xf0e08348 // andq	$-0x10, %rax
	WORD $0x894d; BYTE $0xcb // movq	%r9, %r11
	LONG $0x04ebc149 // shrq	$0x4, %r11
	WORD $0xff49; BYTE $0xc3 // incq	%r11
	WORD $0x8945; BYTE $0xd8 // movl	%r11d, %r8d
	LONG $0x03e08341 // andl	$0x3, %r8d
	LONG $0x30f98349 // cmpq	$0x30, %r9
	JCC LBB2_4
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	WORD $0x8949; BYTE $0xfa // movq	%rdi, %r10
	JMP LBB2_6
LBB2_4:
	LONG $0xfce38349 // andq	$-0x4, %r11
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	WORD $0x8949; BYTE $0xfa // movq	%rdi, %r10
LBB2_5:
	LONG $0x487db262; WORD $0x1431; BYTE $0x0e // vpmovzxbd	(%rsi,%r9), %zmm2
	LONG $0x487df162; WORD $0xd2fe // vpaddd	%zmm2, %zmm0, %zmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xc846fcc5 // kxnorw	%k0, %k0, %k1
	LONG $0x497dd262; WORD $0x1c92; BYTE $0x92 // vgatherdps	(%r10,%zmm2,4), %zmm3 {%k1}
	LONG $0x4874f162; WORD $0xcb58 // vaddps	%zmm3, %zmm1, %zmm1
	QUAD $0x010e5431487db262 // vpmovzxbd	0x10(%rsi,%r9), %zmm2
	LONG $0x487df162; WORD $0xd2fe // vpaddd	%zmm2, %zmm0, %zmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xc846fcc5 // kxnorw	%k0, %k0, %k1
	QUAD $0x00929c92497dd262; WORD $0x0040; BYTE $0x00 // vgatherdps	0x4000(%r10,%zmm2,4), %zmm3 {%k1}
	QUAD $0x020e5431487db262 // vpmovzxbd	0x20(%rsi,%r9), %zmm2
	LONG $0x4874f162; WORD $0xcb58 // vaddps	%zmm3, %zmm1, %zmm1
	LONG $0x487df162; WORD $0xd2fe // vpaddd	%zmm2, %zmm0, %zmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xc846fcc5 // kxnorw	%k0, %k0, %k1
	QUAD $0x00929c92497dd262; WORD $0x0080; BYTE $0x00 // vgatherdps	0x8000(%r10,%zmm2,4), %zmm3 {%k1}
	LONG $0x4874f162; WORD $0xcb58 // vaddps	%zmm3, %zmm1, %zmm1
	QUAD $0x030e5431487db262 // vpmovzxbd	0x30(%rsi,%r9), %zmm2
	LONG $0x487df162; WORD $0xd2fe // vpaddd	%zmm2, %zmm0, %zmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xc846fcc5 // kxnorw	%k0, %k0, %k1
	QUAD $0x00929c92497dd262; WORD $0x00c0; BYTE $0x00 // vgatherdps	0xc000(%r10,%zmm2,4), %zmm3 {%k1}
	LONG $0x4874f162; WORD $0xcb58 // vaddps	%zmm3, %zmm1, %zmm1
	LONG $0x00c28149; WORD $0x0100; BYTE $0x00 // addq	$0x10000, %r10          # imm = 0x10000
	LONG $0x40c18349 // addq	$0x40, %r9
	LONG $0xfcc38349 // addq	$-0x4, %r11
	JNE LBB2_5
LBB2_6:
	WORD $0x8949; BYTE $0xc3 // movq	%rax, %r11
	LONG $0x0ae3c149 // shlq	$0xa, %r11
	WORD $0x854d; BYTE $0xc0 // testq	%r8, %r8
	JE LBB2_9
	WORD $0x0149; BYTE $0xf1 // addq	%rsi, %r9
	LONG $0x04e0c141 // shll	$0x4, %r8d
	WORD $0xdb31 // xorl	%ebx, %ebx
LBB2_8:
	LONG $0x487dd262; WORD $0x1431; BYTE $0x19 // vpmovzxbd	(%r9,%rbx), %zmm2
	LONG $0x487df162; WORD $0xd2fe // vpaddd	%zmm2, %zmm0, %zmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xc846fcc5 // kxnorw	%k0, %k0, %k1
	LONG $0x497dd262; WORD $0x1c92; BYTE $0x92 // vgatherdps	(%r10,%zmm2,4), %zmm3 {%k1}
	LONG $0x4874f162; WORD $0xcb58 // vaddps	%zmm3, %zmm1, %zmm1
	LONG $0x00c28149; WORD $0x0040; BYTE $0x00 // addq	$0x4000, %r10           # imm = 0x4000
	LONG $0x10c38348 // addq	$0x10, %rbx
	WORD $0x3949; BYTE $0xd8 // cmpq	%rbx, %r8
	JNE LBB2_8
LBB2_9:
	WORD $0x014c; BYTE $0xdf // addq	%r11, %rdi
	LONG $0x00c78148; WORD $0x0040; BYTE $0x00 // addq	$0x4000, %rdi           # imm = 0x4000
	LONG $0x10c08348 // addq	$0x10, %rax
LBB2_10:
	LONG $0x48fdf362; WORD $0xc81b; BYTE $0x01 // vextractf64x4	$0x1, %zmm1, %ymm0
	LONG $0x4874f162; WORD $0xc058 // vaddps	%zmm0, %zmm1, %zmm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc8c6f9c5; BYTE $0x01 // vshufpd	$0x1, %xmm0, %xmm0, %xmm1 # xmm1 = xmm0[1,0]
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc816fac5 // vmovshdup	%xmm0, %xmm1    # xmm1 = xmm0[1,1,3,3]
	LONG $0xc158fac5 // vaddss	%xmm1, %xmm0, %xmm0
	WORD $0x8949; BYTE $0xc0 // movq	%rax, %r8
	WORD $0x2949; BYTE $0xd0 // subq	%rdx, %r8
	JGE LBB2_16
	WORD $0x8941; BYTE $0xd1 // movl	%edx, %r9d
	WORD $0x2941; BYTE $0xc1 // subl	%eax, %r9d
	LONG $0x03e18341 // andl	$0x3, %r9d
	JE LBB2_13
LBB2_12:
	LONG $0x14b60f44; BYTE $0x06 // movzbl	(%rsi,%rax), %r10d
	LONG $0x587aa1c4; WORD $0x9704 // vaddss	(%rdi,%r10,4), %xmm0, %xmm0
	LONG $0x00c78148; WORD $0x0004; BYTE $0x00 // addq	$0x400, %rdi            # imm = 0x400
	WORD $0xff48; BYTE $0xc0 // incq	%rax
	WORD $0xff49; BYTE $0xc9 // decq	%r9
	JNE LBB2_12
LBB2_13:
	LONG $0xfcf88349 // cmpq	$-0x4, %r8
	JHI LBB2_16
	LONG $0x00c78148; WORD $0x0008; BYTE $0x00 // addq	$0x800, %rdi            # imm = 0x800
LBB2_15:
	LONG $0x04b60f44; BYTE $0x06 // movzbl	(%rsi,%rax), %r8d
	QUAD $0xf8008784587aa1c4; WORD $0xffff // vaddss	-0x800(%rdi,%r8,4), %xmm0, %xmm0
	LONG $0x44b60f44; WORD $0x0106 // movzbl	0x1(%rsi,%rax), %r8d
	QUAD $0xfc008784587aa1c4; WORD $0xffff // vaddss	-0x400(%rdi,%r8,4), %xmm0, %xmm0
	LONG $0x44b60f44; WORD $0x0206 // movzbl	0x2(%rsi,%rax), %r8d
	LONG $0x587aa1c4; WORD $0x8704 // vaddss	(%rdi,%r8,4), %xmm0, %xmm0
	LONG $0x44b60f44; WORD $0x0306 // movzbl	0x3(%rsi,%rax), %r8d
	QUAD $0x04008784587aa1c4; WORD $0x0000 // vaddss	0x400(%rdi,%r8,4), %xmm0, %xmm0
	LONG $0x04c08348 // addq	$0x4, %rax
	LONG $0x00c78148; WORD $0x0010; BYTE $0x00 // addq	$0x1000, %rdi           # imm = 0x1000
	WORD $0x3948; BYTE $0xc2 // cmpq	%rax, %rdx
	JNE LBB2_15
LBB2_16:
	LONG $0x0111fac5 // vmovss	%xmm0, (%rcx)
	BYTE $0x5b // popq	%rbx
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路scaleAvx512(SB), NOSPLIT, $0-24
	MOVQ a+0(FP), DI
	MOVQ n+8(FP), SI
	MOVQ scalar+16(FP), DX

	WORD $0x8548; BYTE $0xf6 // testq	%rsi, %rsi
	JLE LBB3_9
	LONG $0x487df262; WORD $0x0218 // vbroadcastss	(%rdx), %zmm0
	LONG $0x40fe8348 // cmpq	$0x40, %rsi
	JCS LBB3_4
	WORD $0x8948; BYTE $0xf0 // movq	%rsi, %rax
	LONG $0x06e8c148 // shrq	$0x6, %rax
	WORD $0x8948; BYTE $0xf9 // movq	%rdi, %rcx
LBB3_3:
	LONG $0x0089180f; WORD $0x0002; BYTE $0x00 // prefetcht0	0x200(%rcx)
	LONG $0x487cf162; WORD $0x0959 // vmulps	(%rcx), %zmm0, %zmm1
	LONG $0x487cf162; WORD $0x5159; BYTE $0x01 // vmulps	0x40(%rcx), %zmm0, %zmm2
	LONG $0x487cf162; WORD $0x5959; BYTE $0x02 // vmulps	0x80(%rcx), %zmm0, %zmm3
	LONG $0x487cf162; WORD $0x6159; BYTE $0x03 // vmulps	0xc0(%rcx), %zmm0, %zmm4
	LONG $0x487cf162; WORD $0x0911 // vmovups	%zmm1, (%rcx)
	LONG $0x487cf162; WORD $0x5111; BYTE $0x01 // vmovups	%zmm2, 0x40(%rcx)
	LONG $0x487cf162; WORD $0x5911; BYTE $0x02 // vmovups	%zmm3, 0x80(%rcx)
	LONG $0x487cf162; WORD $0x6111; BYTE $0x03 // vmovups	%zmm4, 0xc0(%rcx)
	LONG $0x00c18148; WORD $0x0001; BYTE $0x00 // addq	$0x100, %rcx            # imm = 0x100
	WORD $0xff48; BYTE $0xc8 // decq	%rax
	JNE LBB3_3
LBB3_4:
	QUAD $0xffffffffffc0b848; WORD $0x7fff // movabsq	$0x7fffffffffffffc0, %rax # imm = 0x7FFFFFFFFFFFFFC0
	WORD $0x2148; BYTE $0xf0 // andq	%rsi, %rax
	WORD $0x8948; BYTE $0xc1 // movq	%rax, %rcx
	WORD $0x2948; BYTE $0xf1 // subq	%rsi, %rcx
	JGE LBB3_9
	WORD $0x8948; BYTE $0xf2 // movq	%rsi, %rdx
	LONG $0x03e28348 // andq	$0x3, %rdx
	JE LBB3_7
LBB3_6:
	LONG $0x0c59fac5; BYTE $0x87 // vmulss	(%rdi,%rax,4), %xmm0, %xmm1
	LONG $0x0c11fac5; BYTE $0x87 // vmovss	%xmm1, (%rdi,%rax,4)
	WORD $0xff48; BYTE $0xc0 // incq	%rax
	WORD $0xff48; BYTE $0xca // decq	%rdx
	JNE LBB3_6
LBB3_7:
	LONG $0xfcf98348 // cmpq	$-0x4, %rcx
	JHI LBB3_9
LBB3_8:
	LONG $0x0c59fac5; BYTE $0x87 // vmulss	(%rdi,%rax,4), %xmm0, %xmm1
	LONG $0x0c11fac5; BYTE $0x87 // vmovss	%xmm1, (%rdi,%rax,4)
	LONG $0x4c59fac5; WORD $0x0487 // vmulss	0x4(%rdi,%rax,4), %xmm0, %xmm1
	LONG $0x4c11fac5; WORD $0x0487 // vmovss	%xmm1, 0x4(%rdi,%rax,4)
	LONG $0x4c59fac5; WORD $0x0887 // vmulss	0x8(%rdi,%rax,4), %xmm0, %xmm1
	LONG $0x4c11fac5; WORD $0x0887 // vmovss	%xmm1, 0x8(%rdi,%rax,4)
	LONG $0x4c59fac5; WORD $0x0c87 // vmulss	0xc(%rdi,%rax,4), %xmm0, %xmm1
	LONG $0x4c11fac5; WORD $0x0c87 // vmovss	%xmm1, 0xc(%rdi,%rax,4)
	LONG $0x04c08348 // addq	$0x4, %rax
	WORD $0x3948; BYTE $0xc6 // cmpq	%rax, %rsi
	JNE LBB3_8
LBB3_9:
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路squaredL2Avx512(SB), NOSPLIT, $0-32
	MOVQ vec1+0(FP), DI
	MOVQ vec2+8(FP), SI
	MOVQ n+16(FP), DX
	MOVQ result+24(FP), CX

	LONG $0x3f428d4c // leaq	0x3f(%rdx), %r8
	WORD $0x8548; BYTE $0xd2 // testq	%rdx, %rdx
	LONG $0xc2490f4c // cmovnsq	%rdx, %r8
	WORD $0x894d; BYTE $0xc1 // movq	%r8, %r9
	LONG $0xc0e18349 // andq	$-0x40, %r9
	WORD $0x8948; BYTE $0xd0 // movq	%rdx, %rax
	WORD $0x294c; BYTE $0xc8 // subq	%r9, %rax
	LONG $0xc057f8c5 // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x40fa8348 // cmpq	$0x40, %rdx
	JLT LBB1_4
	LONG $0x06f8c149 // sarq	$0x6, %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	LONG $0xc957f0c5 // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0xd257e8c5 // vxorps	%xmm2, %xmm2, %xmm2
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
LBB1_2:
	QUAD $0x0002000f8c180f42; BYTE $0x00 // prefetcht0	0x200(%rdi,%r9)
	QUAD $0x0002000e8c180f42; BYTE $0x00 // prefetcht0	0x200(%rsi,%r9)
	LONG $0x487cb162; WORD $0x2410; BYTE $0x0f // vmovups	(%rdi,%r9), %zmm4
	QUAD $0x010f6c10487cb162 // vmovups	0x40(%rdi,%r9), %zmm5
	QUAD $0x020f7410487cb162 // vmovups	0x80(%rdi,%r9), %zmm6
	QUAD $0x030f7c10487cb162 // vmovups	0xc0(%rdi,%r9), %zmm7
	LONG $0x485cb162; WORD $0x245c; BYTE $0x0e // vsubps	(%rsi,%r9), %zmm4, %zmm4
	QUAD $0x010e6c5c4854b162 // vsubps	0x40(%rsi,%r9), %zmm5, %zmm5
	QUAD $0x020e745c484cb162 // vsubps	0x80(%rsi,%r9), %zmm6, %zmm6
	QUAD $0x030e7c5c4844b162 // vsubps	0xc0(%rsi,%r9), %zmm7, %zmm7
	LONG $0x485df262; WORD $0xc4b8 // vfmadd231ps	%zmm4, %zmm4, %zmm0 # zmm0 = (zmm4 * zmm4) + zmm0
	LONG $0x4855f262; WORD $0xcdb8 // vfmadd231ps	%zmm5, %zmm5, %zmm1 # zmm1 = (zmm5 * zmm5) + zmm1
	LONG $0x484df262; WORD $0xd6b8 // vfmadd231ps	%zmm6, %zmm6, %zmm2 # zmm2 = (zmm6 * zmm6) + zmm2
	LONG $0x4845f262; WORD $0xdfb8 // vfmadd231ps	%zmm7, %zmm7, %zmm3 # zmm3 = (zmm7 * zmm7) + zmm3
	LONG $0x00c18149; WORD $0x0001; BYTE $0x00 // addq	$0x100, %r9             # imm = 0x100
	WORD $0xff49; BYTE $0xc8 // decq	%r8
	JNE LBB1_2
	LONG $0x4874f162; WORD $0xc058 // vaddps	%zmm0, %zmm1, %zmm0
	LONG $0x4864f162; WORD $0xca58 // vaddps	%zmm2, %zmm3, %zmm1
	LONG $0x4874f162; WORD $0xc058 // vaddps	%zmm0, %zmm1, %zmm0
LBB1_4:
	LONG $0x48fdf362; WORD $0xc11b; BYTE $0x01 // vextractf64x4	$0x1, %zmm0, %ymm1
	LONG $0x487cf162; WORD $0xc158 // vaddps	%zmm1, %zmm0, %zmm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$0x1, %ymm0, %xmm1
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc8c6f9c5; BYTE $0x01 // vshufpd	$0x1, %xmm0, %xmm0, %xmm1 # xmm1 = xmm0[1,0]
	LONG $0xc158f8c5 // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc816fac5 // vmovshdup	%xmm0, %xmm1    # xmm1 = xmm0[1,1,3,3]
	LONG $0xc158fac5 // vaddss	%xmm1, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE LBB1_7
	WORD $0x8949; BYTE $0xd0 // movq	%rdx, %r8
	WORD $0x2949; BYTE $0xc0 // subq	%rax, %r8
LBB1_6:
	LONG $0x107aa1c4; WORD $0x870c // vmovss	(%rdi,%r8,4), %xmm1
	LONG $0x5c72a1c4; WORD $0x860c // vsubss	(%rsi,%r8,4), %xmm1, %xmm1
	LONG $0xb971e2c4; BYTE $0xc1 // vfmadd231ss	%xmm1, %xmm1, %xmm0 # xmm0 = (xmm1 * xmm1) + xmm0
	WORD $0xff49; BYTE $0xc0 // incq	%r8
	WORD $0x3949; BYTE $0xd0 // cmpq	%rdx, %r8
	JLT LBB1_6
LBB1_7:
	LONG $0x0111fac5 // vmovss	%xmm0, (%rcx)
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

